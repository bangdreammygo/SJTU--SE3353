# 应用体系架构（大三上） SE十二童首(11-20)

上面的所有内容是关于服务端的问题，从这里开始讲数据库的知识：

- 关系型数据库的优化
- 非关系型数据库（5种：mongoDB，influxDB，图数据库等）

# 11-MySQL OPT1

### 多层次优化的方面（这部分的目录）

- #### 数据库层次

  表的结构的合理性：

  - 是否每列的数据类型合(char,varchar); 
  - 合适的索引; 
  - 存储引擎：Mysql主要是InnoDB;
  - 行格式：比如学号前几位一样可以压缩之类的
  - 锁机制
  - caching配置大小

- #### 硬件层次

  - 磁盘寻址操作
  - 磁盘的读写：HDD和SSD
  - CPU和内存

不管怎么优化必须平衡可移植性和性能，在使用SQL的extension功能后要使用/ * ! * /注释声明

## 索引

### **作用**

在使用SELECT操作时，在一列或者多列上创建索引会加快搜索速度。

- **举例1：**大部分是B树和B+树索引，第一个好处是建立一个多叉树，考虑到了内存页的尺寸，每次读入数据时不会有很多的空间浪费；第二个好处叶子节点有指向兄弟节点的指针，范围搜索很快；

- **举例2：**空间索引用R tree，mongoDB详述；内存里临时表索引使用哈希map，比较浪费空间（桶源多一点）

- **举例3：**InnoDB使用inverted lists进行FULLTEXT 索引

- **举例4：** Cluster Index聚簇索引（树中兄弟节点的顺序和物理存储的顺序一致）默认在主键上建立，可以建到经常搜索的数据上；一个表一个。

  ps：B树和哈希比较

  - B树适合做范围查找，也适合like查找（但是第一个前缀不能是通配符）始终是最左索引
  - 哈希索引适合对于=或者不=十分友好，不可以排序

**具体应用在哪些操作上？**

- 快速查找与WHERE子句匹配的行。
- 从考虑中排除行。
- 如果表具有多列索引，则可以使用索引的最左边的任何前缀来查找行。
- 在执行连接时从其他表检索行。
- 查找特定索引列key_col的MIN（）或MAX（）值。
- 如果排序或分组是在可用索引的最左边的前缀上完成的，则对表进行排序或分组（例如，ORDER BY key_part1, key_part2）。
- 在某些情况下，可以对查询进行优化，以便在不查询数据行的情况下检索值。

### **实质**

把那一列的东西都搬了出来建了一棵树，所以空间大小其实就是做了一个 duplication。我们在支持的时候，是把索引 load 到内存里的，索引命中的时候，就对应的硬盘上的位置，我们就可以直接寻址过去。

- 建立索引要花费时间和空间，维护一颗树也需要成本
- 追求一个平衡，如果表本身就很小，索引的成本超过了scan的成本，所以不需要索引。

### 主键和外键

- 主键如果由太多的列构成，那么这个建立索引的效率就不太好，可以生成一个**基于整数递增**的列来建立索引
- 主键是默认不为空的，但是如果在**为空的列上上建立索引**有3个坏处：
  - 允许某列为空是在这个存储单元之后最后一个bit位，用01表示是否为空，空间浪费
  - Mysql操作时总是要check是否为空，浪费时间
  -  <img src="C:\Users\77043\Desktop\应用\11-12\1.jpg" alt="1" style="zoom:30%;" />挂一串很长null的东西，索引失去意义，所以最好设计不为空

可以把使用频率比较低的数据列和其他分开（比如：书籍简介单独开一张表，使用bookid关联）好处：

- 可以一次读入更多更常使用的数据
- 可以把这些放入其他数据库（图数据库。。。）

### 列索引

如果一列太长怎么建索引？可以只使用前N个字串来索引（比如只搜索title的前3个词）

N怎么选择：行格式REDUNDANT COMPACT  DYNAMIC  COMPRESSED（4种范围决定了N）

前面讲过的全文索引只附一张图：

<img src="C:\Users\77043\AppData\Roaming\Typora\typora-user-images\image-20250114214650019.png" alt="image-20250114214650019" style="zoom:67%;" />

### 多列索引

最多再16列上创建索引，是按照靠前靠左的方式查询的，不能搞反了。（最左索引）

<img src="C:\Users\77043\AppData\Roaming\Typora\typora-user-images\image-20250114214857175.png" alt="image-20250114214857175" style="zoom:67%;" />

索引可以有升序降序：不同列的升降属于不同的索引

## 数据库结构

目标：最小化IO；相关联的项在一起；是否分表分区

### 数据存储尺寸

- 数据库的列：使用比较小的数据类型，尽量设置为不为空；
- 行格式：REDUNDANT < COMPACT  DYNAMIC  COMPRESSED（把前几位一样的落盘时压缩/存浮动）
- 索引：主键越短越好，基于整数递增（8）/UUID（16）;UUID是生成策略简单，但是不好索引。
- join操作：字段信息应该完全一样两个表里面的booid名字数据类型必须一样，速度会快很多。
- 范式化Normaization：消除冗余数据，但是不能范式化程度太高，否则会效率低下

### 数据类型

- 数值型：字符串（浪费）   or   数值（省空间）学号用数值型：快省空间，避免解析字符串的时间
- 字符型：使用相同的数据集（UTF-8或者Unicode）varchar（尺寸小于8k）BlOB（大于8k，只存一个指针）
- BLOB字段：把很长的东西放到另外的地方只是load进很多指针，效率高不少

### 表的数目

打开一个表会放到一个缓存里面，使用多版本的并发MVCC，每个并发里面都会开一个表（靠log统一）

MySQL对于数据库的数量无限制，对于表也无上限；由操作系统对文件系统的上限决定

表的尺寸：也由操作系统对文件系统的上限决定。最多4096列，行的尺寸：一行最多64kb（65535），varchar，TEXT和BLOB（基本可以的）varchar除了写出来的大小，还需要有1-2个bit存储到底放了几个，所以不可以varchar（65535）。char不能大于页面的一半大小。

<img src="C:\Users\77043\AppData\Roaming\Typora\typora-user-images\image-20250114223717045.png" alt="image-20250114223717045" style="zoom:40%;" /> <img src="C:\Users\77043\AppData\Roaming\Typora\typora-user-images\image-20250114223736004.png" alt="image-20250114223736004" style="zoom:50%;" /> 

![image-20250114223817550](C:\Users\77043\AppData\Roaming\Typora\typora-user-images\image-20250114223817550.png)

![image-20250114223842480](C:\Users\77043\AppData\Roaming\Typora\typora-user-images\image-20250114223842480.png)

# 12-MySQL OPT2

### 总述：

- **OPT InnoDB Table**
- **OPT  MEMORY Table**
- **Buffering  and  Caching**

## **OPT InnoDB Table**

- **OPTIMIZE TABLE：**数据库到达一定级别后数据基本稳定之后可以进行一次（OPTIMIZE TABLE）：把一块一块的数据copy放到一起，然后重新建立索引（减少碎片的数目，速度会变快，但是这次操作会浪费时间，隔一段时间做）。
- 尽量使用**varchar**：可以压缩，但是缺点是需要一个额外的位去维持varchar里有几个；允许为空用varchar
- **char**：如果学号很长很长，大家每个人的位数都一样，使用char合理
- **事务：**执行每一条SQL语句，都默认在一个事务里，每条语句一个事务。（AUTOCOMMIT决定的）但是频繁的落盘会效率比较低，所以可以手动划分事务边界。---->但是需要避免一个大事务里修改大量的行（roolback时候系统性能极其差）如果实在避免不了，尽量少commit。同时避免长时间运行的事务，因为会上锁导致其他事务无法进行，如果要降低事务隔离级别使其可以，会出现更多问题。
- **缓冲池（buffer pool）：** 尽可能稍微大一点，我们写完之后，会先缓存，不会立马落盘，性能提高。
- **READ-Only事务：** 开始事务之前声明 START TRANSACTION ONLY，不会回滚，select无锁
- **批量数据导入InnoDB表：** 可以先关掉autocommit，不会创建海量事务，无数次提交。只需要在都结束之后提交即可。（如果插入唯一UN的数据：这么做的前提是必须确认没有重复的；如果插入有外键的，也可以这么做）插入多行可以写single SQL 用INSERT (1,2)，(3,4)....; 批量数据时自增的锁的模式是2(interleaved)不是1(consecutive).
- **查询优化：** 每个表有主键，怎么优化见OPT1.（1.聚簇索引  2.主键不要太长，不要太多）
- **磁盘IO：**
  - 把缓存池增大，事务执行NO-Steal，NO-Force（内存上来）
  - 调整落盘时的策略 O_DSYNC（文件属性）
  - 配置文件同步的阈值（填一个具体数值使其周期性的往磁盘上刷）
  - 找非旋转的存储（不用HDD，对随机的IO比较差），用SSD处理随机的IO
  - 提高IO性能避免经常做的日志。**checkpoint** ：从t1到t2的增量，到一定时间做全量一次（涉及大量的IO）。
- **优化DDL**：删除表中的所有数据，使用TRUNCATE(直接把后续的指针置为空)不要使用DELETE *(一条一条删)，但是有外键的时候要注意顺序问题，主键一旦被创建尽量不要修改了。

## **OPT  MEMORY Table**

内存里的数据放一些常用的但是不能放关键的，容易丢，默认是哈希查找，但是也可以根据需求修改成B树。

## Buffering and Caching

- #### 缓存池尺寸

  pool 由一个一个的chunk组成，每个chunk size默认是128M，所以pool size必须是chunksize 的整数倍，所以你规定9G（只是一个建议），他会开成10G。

- #### 多个缓存池的实例

  减少不同进程对cached page 的竞争访问，实例多了，每个池的大小会变小，要做一个平衡。最多可以开到64个，最小得是1G。

- #### 抵抗扫描

  我们不是使用严格的LRU策略决定缓存池里放什么东西。放到LRU一半的位置（3/8的位置），很快被替换，保证数据hot性。甚至可以分segment，分开放热度不同的数据，保证热数据。

- #### 预读

  HDD磁盘转到这里的时候，我们会乘磁盘转的时候多读一些数据到缓存池里。（线性读出来前后/随机读出）

- #### Flushing

  缓存里的东西什么时候落盘。记录所有的脏页（更改过数据的没落下去）。**有几个线程负责脏页落盘**（默认是4个）？但是不会超过线程池的实例个数。**落下去的时间**？脏页的水位线，大概是10%。

- #### 保存和恢复缓存池状态

  会在服务器关闭时，把最常用的页存在硬盘上，启动时从硬盘上直接恢复。dump的百分比可以设置。





------

# 13-mysql backup & recovery 

+ 备份你的数据库很重要
  + 这样，您可以恢复数据，并在出现问题时再次启动并运行，例如系统崩溃、硬件故障或用户错误删除数据。
  + 在升级MySQL安装之前（比如mysql5升级到mysql8），备份也是必不可少的保障措施，它们可用于将MySQL安装传输到另一个系统或设置副本服务器。

+ 应该熟悉的几个备份和恢复主题(topic)：
  + 备份类型：逻辑备份与物理备份、完整备份与增量备份等。
  + 创建备份的方法。
  + 恢复方法，包括时间点恢复。
  + 备份调度、压缩和加密。
  + 表维护，以恢复损坏的表。

## 物理备份与逻辑备份

### 物理备份（原始备份）

- **定义**：由存储数据库内容的目录和文件的原始副本组成。
- **特点**：
  - 直接复制数据库的物理文件（如数据文件、日志文件）。
  - 恢复速度快，适合大型重要数据库。
- **适用场景**：
  - 需要快速恢复的数据库。
  - 大规模数据备份和灾难恢复。

### 逻辑备份

- **定义**：保存以逻辑数据库结构（如 `CREATE DATABASE`、`CREATE TABLE` 语句）和内容（如 `INSERT` 语句或分隔文本文件）表示的信息。
- **特点**：
  - 以逻辑数据结构为单位进行备份。
  - 可编辑数据值或表结构，适合跨平台迁移。
- **适用场景**：
  - 较小的数据量。
  - 需要选择性恢复或数据迁移的场景。
  - 在不同机器架构上重新创建数据。

### 对比总结

| **特性**         | **物理备份**                           | **逻辑备份**                     |
| ---------------- | -------------------------------------- | -------------------------------- |
| **备份内容**     | 数据库的物理文件（数据文件、日志文件） | 逻辑结构（SQL 语句或文本文件）   |
| **恢复速度**     | 快                                     | 较慢                             |
| **适用场景**     | 大型数据库、快速恢复                   | 小型数据库、数据迁移、选择性恢复 |
| **跨平台兼容性** | 依赖存储结构，平台相关                 | 可跨平台使用                     |
| **编辑灵活性**   | 不可编辑                               | 可编辑数据值或表结构             |

## 在线备份与离线备份

### 在线备份

- **定义**：在 MySQL 服务器运行时进行备份，直接从服务器获取数据库信息。
- **特点**：
  - 服务器保持运行状态。
  - 备份过程对其他客户端的影响较小。
  - 客户端可以在备份期间连接并访问数据（取决于操作类型）。
- **注意事项**：
  - 需要实施适当的锁定机制，以防止数据修改影响备份完整性。
  - MySQL 企业备份产品会自动处理此类锁定。
- **适用场景**：
  - 需要高可用性的系统。
  - 不允许停机的生产环境。

### 离线备份

- **定义**：在 MySQL 服务器停止时进行备份。
- **特点**：
  - 服务器完全停止运行。
  - 备份过程不会受到数据修改的影响。
  - 备份期间客户端无法访问数据库。
- **注意事项**：
  - 由于服务器在备份期间不可用，客户端可能会受到不利影响。
  - 通常从副本进行备份，以避免影响主服务器的可用性。
  - 备份程序更简单，因为没有客户端活动干扰的可能性。
- **适用场景**：
  - 允许停机的维护窗口。
  - 对数据一致性要求极高的场景。

### 热备份、冷备份与暖备份

- **热备份（在线备份）**：
  - 服务器运行，数据可访问。
  - 备份过程中允许数据修改（需锁定机制）。
- **冷备份（离线备份）**：
  - 服务器停止，数据不可访问。
  - 备份过程中无数据修改。
- **暖备份**：
  - 服务器运行，但数据库文件被锁定，防止数据修改。
  - 允许外部访问数据库文件。

### 在线备份的特点

1. **侵入性较小**：
   - 备份期间客户端可以连接并访问数据。
   - 对业务影响较小。
2. **锁定机制**：
   - 必须确保备份期间数据不被修改。
   - MySQL 企业备份产品会自动处理锁定。
3. **适用性**：
   - 适合需要高可用性和持续运行的系统。

### 离线备份的特点

1. **客户端影响**：
   - 服务器在备份期间不可用，客户端可能会受到不利影响。
   - 通常从副本进行备份，以避免影响主服务器的可用性。
2. **备份程序简单**：
   - 没有客户端活动干扰的可能性。
   - 备份过程更稳定，数据一致性更高。

### 恢复操作的在线与离线

- **在线恢复**：
  - 服务器运行，但恢复过程需要更强的锁定机制。
  - 客户端比在线备份更有可能受到影响，因为恢复会修改数据。
  - 必须阻止客户端访问数据，以确保恢复的完整性。
- **离线恢复**：
  - 服务器停止运行，恢复过程不受客户端活动干扰。
  - 适合对数据一致性要求极高的场景。

### 对比总结

| **特性**       | **在线备份**                 | **离线备份**             |
| -------------- | ---------------------------- | ------------------------ |
| **服务器状态** | 运行中                       | 停止                     |
| **数据访问**   | 客户端可访问（需锁定机制）   | 客户端不可访问           |
| **备份完整性** | 需锁定机制防止数据修改       | 无数据修改，完整性高     |
| **适用场景**   | 高可用性、不允许停机的系统   | 允许停机的维护窗口       |
| **客户端影响** | 较小（需锁定机制）           | 较大（服务器不可用）     |
| **恢复操作**   | 需更强锁定，客户端可能受影响 | 无客户端干扰，恢复更稳定 |

## 本地备份与远程备份

### 本地备份

- **定义**：在运行 MySQL 服务器的同一主机上执行备份。
- **特点**：
  - 备份文件直接存储在服务器主机上。
  - 适用于小型数据库或单机环境。
- **工具示例**：
  - `mysqldump`（可本地连接）。
  - `SELECT ... INTO OUTFILE`（输出文件在服务器主机上创建）。

### 远程备份

- **定义**：从不同的主机连接到 MySQL 服务器进行备份。
- **特点**：
  - 备份文件可以存储在远程主机上。
  - 适用于分布式环境或需要异地备份的场景。
- **工具示例**：
  - `mysqldump`（可远程连接）。
  - 物理备份方法（如文件复制到远程目的地）。

### 快照备份

- **定义**：利用文件系统的快照功能，创建文件系统在某一时间点的逻辑副本。
- **特点**：
  - 不需要复制整个文件系统。
  - 使用copy on write技术，仅复制快照后修改的部分。
- **实现方式**：
  - MySQL 本身不支持快照功能。
  - 依赖第三方解决方案（如 Veritas、LVM 或 ZFS）。
- **适用场景**：
  - 需要快速备份和恢复的大型数据库。
  - 对备份速度和存储空间有较高要求的场景。

### 对比总结

| **特性**     | **本地备份**                           | **远程备份**              | **快照备份**                   |
| ------------ | -------------------------------------- | ------------------------- | ------------------------------ |
| **执行位置** | 服务器主机                             | 远程主机                  | 服务器主机（依赖文件系统）     |
| **存储位置** | 服务器主机                             | 远程主机                  | 服务器主机                     |
| **适用场景** | 小型数据库、单机环境                   | 分布式环境、异地备份      | 大型数据库、快速备份与恢复     |
| **依赖工具** | `mysqldump`、`SELECT ... INTO OUTFILE` | `mysqldump`、物理备份方法 | Veritas、LVM、ZFS 等第三方工具 |


## 完整备份与增量备份

### 完整备份

- **定义**：备份 MySQL 服务器在给定时间点管理的所有数据。
- **特点**：
  - 包含所有数据，恢复简单。
  - 占用存储空间较大。
- **适用场景**：
  - 首次备份。
  - 定期全量备份。

### 增量备份

- **定义**：备份在给定时间段内（从一个时间点到另一个时间点）对数据所做的更改。
- **特点**：
  - 仅备份变化的数据，节省存储空间。
  - 恢复时需要依赖完整备份和所有增量备份。
- **实现方式**：
  - 启用服务器的二进制日志，记录数据更改。
- **适用场景**：
  - 频繁备份。
  - 节省存储空间。

## 备份调度、压缩和加密

### 备份调度

- **定义**：自动化备份程序，按计划执行备份任务。
- **优点**：
  - 减少人为操作错误。
  - 确保备份的及时性和一致性。

### 备份压缩

- **定义**：压缩备份输出，减少存储空间需求。
- **优点**：
  - 节省存储空间。
  - 提高备份效率。
- **实现方式**：
  - MySQL 企业备份产品支持 InnoDB 备份压缩。
  - 使用文件系统实用程序（如 gzip）进行压缩。

### 备份加密

- **定义**：加密备份输出，防止未经授权访问。
- **优点**：
  - 提高数据安全性。
  - 防止数据泄露。
- **实现方式**：
  - 使用文件系统实用程序（如 OpenSSL）进行加密。
  - 第三方解决方案可能提供更多功能。

## 使用 MySQL 企业备份进行热备份

### MySQL 企业备份

- **定义**：MySQL 企业版客户可以使用 MySQL 企业备份产品进行物理备份。
- **特点**：
  - 支持对整个实例、选定的数据库或表进行备份。
  - 提供增量和压缩备份功能。
  - 备份物理数据库文件，恢复速度比逻辑备份（如 `mysqldump`）快。
- **备份机制**：
  - **InnoDB 表**：使用热备份机制（服务器运行，数据可访问）。
  - **其他存储引擎表**：使用暖备份机制（服务器运行，但锁定数据文件）。
- **适用场景**：
  - 需要快速恢复的大型数据库。
  - 对备份速度和存储空间有较高要求的场景。

## 使用 `mysqldump` 进行备份

### `mysqldump` 备份

- **定义**：`mysqldump` 程序可以备份各种表。
- **特点**：
  - 支持逻辑备份，生成 SQL 文件。
  - 对于 InnoDB 表，可以使用 `--single-transaction` 选项执行在线备份，不锁定表。（在备份过程中别人只读不写）
- **适用场景**：
  - 小型数据库或需要跨平台迁移的场景。
  - 需要选择性备份或编辑数据的场景。

## 通过复制表文件进行备份

### MyISAM 表备份

- **方法**：复制表文件（`*.MYD`、`*.MYI` 和 `*.sdi` 文件）。

- **步骤**：

  1. 停止服务器或锁定并刷新相关表：（刷盘，读锁）

     ```sql
     FLUSH TABLES tbl_list WITH READ LOCK;
     ```

  2. 复制数据库目录中的表文件。

  3. 释放锁：

     ```sql
     UNLOCK TABLES;
     ```

- **特点**：

  - 只需读取锁，允许其他客户端继续查询表。
  - 需要刷新以确保所有活动索引页面写入磁盘。

- **限制**：

  - 不适用于 InnoDB 表。
  - InnoDB 可能缓存数据在内存中，未刷新到磁盘。

## 进行分隔文本文件备份

### 使用 `SELECT ... INTO OUTFILE`

- **方法**：将表数据导出为文本文件。

  ```sql
  SELECT * INTO OUTFILE 'file_name' FROM tbl_name;
  ```

- **特点**：

  - 文件在 MySQL 服务器主机上创建。
  - 输出文件不能已存在（防止安全风险）。
  - 仅保存表数据，不保存表结构。

- **适用场景**：

  - 需要导出表数据的场景。

### 使用 `mysqldump` 的 `--tab` 选项

- **方法**：生成分隔文本数据文件和表结构文件。

  ```bash
  mysqldump --tab=/path/to/output/dir db_name tbl_name
  ```

- **特点**：

  - 生成两个文件：数据文件（`.txt`）和表结构文件（`.sql`）。
  - 适合需要同时备份数据和结构的场景。

### 重新加载分隔文本文件

- **方法**：使用 `LOAD DATA` 或 `mysqlimport`。

  ```sql
  LOAD DATA INFILE 'file_name' INTO TABLE tbl_name;
  ```

  ```bash
  mysqlimport db_name file_name
  ```

- **适用场景**：

  - 需要快速导入数据的场景。

## 使用二进制日志进行增量备份

### 增量备份

- **定义**：MySQL 支持使用二进制日志进行增量备份。
- **特点**：
  - 二进制日志文件记录了数据库的所有更改。
  - 增量备份包含自上次完整备份或增量备份以来的所有更改。
- **步骤**：
  1. 在需要创建增量备份时，使用 `FLUSH LOGS` 命令轮换二进制日志。
  2. 下次进行完整备份时，同样使用 `FLUSH LOGS` 或 `mysqldump --flush-logs` 轮换二进制日志。
- **适用场景**：
  - 需要频繁备份且节省存储空间的场景。

## 使用副本进行备份（主从备份）

### 副本备份

- **定义**：如果备份时主服务器性能受到影响，可以通过设置复制并在副本上进行备份。
- **特点**：
  - 备份副本而非源服务器，减少对主服务器的影响。
  - 需要备份副本的连接元数据存储库和应用元数据存储库。
- **注意事项**：
  - 如果副本正在复制 `LOAD DATA` 语句，还需备份 `SQL_LOAD-*` 文件。
  - 这些文件用于恢复中断的 `LOAD DATA` 操作。
- **适用场景**：
  - 高负载生产环境，需要减少备份对主服务器的影响。

## 恢复损坏的表

### 恢复方法

- **MyISAM 表恢复**：
  - 使用 `REPAIR TABLE` 或 `myisamchk -r` 命令尝试修复损坏的表。
  - 在 99.9% 的情况下可以成功修复。
- **适用场景**：
  - 表损坏但数据未完全丢失的情况。

## 使用文件系统快照进行备份

### Veritas 文件系统快照

- **步骤**：
  1. 在客户端程序中执行 `FLUSH TABLES WITH READ LOCK`。
  2. 在另一个 shell 中执行 `mount vxfs snapshot`。
  3. 在第一个客户端中执行 `UNLOCK TABLES`。
  4. 从快照中复制文件。
  5. 卸载快照。
- **其他文件系统**：
  - 类似功能也可在 LVM 或 ZFS 等文件系统中使用。
- **适用场景**：
  - 需要快速备份和恢复的大型数据库。

### 对比总结

| **备份方法**           | **特点**                                           | **适用场景**               |
| ---------------------- | -------------------------------------------------- | -------------------------- |
| **二进制日志增量备份** | 记录数据库更改，节省存储空间                       | 频繁备份、节省存储空间     |
| **副本备份**           | 减少对主服务器的影响，需备份元数据                 | 高负载生产环境             |
| **表恢复**             | 使用 `REPAIR TABLE` 或 `myisamchk -r` 修复损坏的表 | 表损坏但数据未完全丢失     |
| **文件系统快照备份**   | 快速备份和恢复，依赖文件系统快照功能               | 大型数据库、快速备份与恢复 |

## 备份与恢复策略

### 备份目标

- **恢复场景**：
  - 操作系统崩溃
  - 电源故障
  - 文件系统崩溃
  - 硬件问题（硬盘、主板等）
- **假设条件**：
  - 数据存储在支持事务和自动崩溃恢复的 `InnoDB` 存储引擎中。
  - MySQL 服务器在崩溃时处于负载状态。

## 操作系统崩溃或电源故障

### 恢复机制

- **数据可用性**：
  - MySQL 磁盘数据在重启后仍然可用。
- **InnoDB 自动恢复**：
  - `InnoDB` 读取日志文件，找到未刷新到数据文件的已提交和未提交事务。
  - 自动回滚未提交的事务，并将已提交的事务刷新到数据文件。
- **恢复步骤**：
  - 无需手动干预，`InnoDB` 自动完成恢复。

## 文件系统崩溃或硬件问题

### 恢复机制

- **数据不可用**：
  - MySQL 磁盘数据在重启后不可用。
  - 需要重新格式化磁盘、更换硬盘或修复硬件问题。
- **恢复步骤**：
  1. 修复硬件问题。
  2. 从备份中恢复 MySQL 数据。
  3. 确保备份策略已实施。

## 制定备份策略

### 完整备份

- **命令**：

  ```bash
  mysqldump --all-databases --master-data --single-transaction > backup_sunday_1_PM.sql
  ```

- **特点**：

  - 每周日 1 点进行完整备份。
  - 生成包含 SQL `INSERT` 语句的 `.sql` 文件。
  - 在备份开始时获取全局读锁。

- **适用场景**：

  - 定期全量备份。

### 增量备份

- **启用二进制日志**：

  - 启动 MySQL 服务器时使用 `--log-bin` 选项。
  - 二进制日志记录所有数据更改。

- **清理二进制日志**：

  ```bash
  mysqldump --single-transaction --flush-logs --master-data=2 \
            --all-databases --delete-master-logs > backup_sunday_1_PM.sql
  ```

- **适用场景**：

  - 频繁备份，节省存储空间。

## 使用备份进行恢复

### 恢复步骤

1. **恢复完整备份**：

   ```bash
   mysql < backup_sunday_1_PM.sql
   ```

   - 数据恢复到周日 1 点的状态。

2. **恢复增量备份**：

   - 使用二进制日志文件（如 `gbichot2-bin.000007` 和 `gbichot2-bin.000008`）：

     ```bash
     mysqlbinlog gbichot2-bin.000007 gbichot2-bin.000008 | mysql
     ```

   - 数据恢复到周二 1 点的状态。

3. **恢复最新更改**：

   - 如果二进制日志存储在安全位置（如 RAID 磁盘、SAN），可以恢复崩溃前的数据：

     ```bash
     mysqlbinlog gbichot2-bin.000009 ... | mysql
     ```

## 备份策略总结

### 关键点

1. **启用二进制日志**：
   - 默认情况下，MySQL 8.0 启用二进制日志。
   - 将二进制日志存储在与数据目录不同的物理设备上，以提高安全性。

2. **定期完整备份**：
   - 使用 `mysqldump` 进行在线、非阻塞的完整备份。

3. **定期增量备份**：
   - 使用 `FLUSH LOGS` 或 `mysqladmin flush-logs` 刷新日志，创建增量备份。

4. **自动恢复**：
   - 在操作系统崩溃或电源故障时，`InnoDB` 自动完成数据恢复。

### 对比总结

| **备份类型**       | **特点**                                    | **适用场景**           |
| ------------------ | ------------------------------------------- | ---------------------- |
| **完整备份**       | 包含所有数据，恢复简单                      | 定期全量备份           |
| **增量备份**       | 仅备份变化数据，节省存储空间                | 频繁备份、节省存储空间 |
| **二进制日志恢复** | 记录所有数据更改，用于恢复增量备份          | 崩溃后恢复最新数据     |
| **自动恢复**       | `InnoDB` 自动回滚未提交事务并刷新已提交事务 | 操作系统崩溃或电源故障 |

## MySQL Shell 导出工具

### 特点

- **并行导出**：支持多线程导出，提高效率。
- **文件压缩**：减少存储空间占用。
- **进度显示**：实时显示导出进度。
- **云功能**：
  - 支持 Oracle Cloud Infrastructure Object Storage 流式传输。
  - 提供 MySQL Database Service 兼容性检查和修改。
- **导入工具**：使用 MySQL Shell 的 `load dump` 工具轻松导入数据。

### 用途

1. **数据备份**：用于数据丢失时的恢复。
2. **副本设置**：作为设置副本的数据源。
3. **数据实验**：
   - 创建数据库副本，不影响原始数据。
   - 测试潜在的升级不兼容性。

## mysqldump` 工具

### 输出类型

1. **SQL 格式输出**：

   - 默认输出格式。

   - 包含 `CREATE` 语句（创建数据库、表、存储过程等）和 `INSERT` 语句（插入数据）。

   - 保存为文件后，可使用 `mysql` 重新加载。

   - 示例：

     ```bash
     mysqldump [arguments] > file_name
     ```

2. **分隔文本格式输出**：

   - 使用 `--tab` 选项。

   - 每个表生成两个文件：

     - `tbl_name.sql`：包含 `CREATE TABLE` 语句。
     - `tbl_name.txt`：包含表数据，每行一条记录。

   - 示例：

     ```bash
     mysqldump --tab=/tmp db1
     ```

## 使用 `mysqldump` 导出数据

### 导出所有数据库

```bash
mysqldump --all-databases > dump.sql
```

### 导出指定数据库

```bash
mysqldump --databases db1 db2 db3 > dump.sql
```

### 导出单个数据库

```bash
mysqldump --databases test > dump.sql
```

或

```bash
mysqldump test > dump.sql
```

### 导出指定表

```bash
mysqldump test t1 t3 t7 > dump.sql
```

## 重新加载 SQL 格式备份

### 加载包含多个数据库的备份

```bash
mysql < dump.sql
```

或在 `mysql` 客户端中：

```sql
source dump.sql;
```

### 加载单个数据库备份

1. 创建数据库（如果需要）：

   ```bash
   mysqladmin create db1
   ```

2. 加载备份文件：

   ```bash
   mysql db1 < dump.sql
   ```

   或在 `mysql` 客户端中：

```sql
CREATE DATABASE IF NOT EXISTS db1;
USE db1;
source dump.sql;
```

## 重新加载分隔文本格式备份

### 加载步骤

1. 进入输出目录。

2. 使用 `mysql` 加载 `.sql` 文件创建表：

   ```bash
   mysql db1 < t1.sql
   ```

3. 使用 `mysqlimport` 或 `LOAD DATA` 加载 `.txt` 文件：

   ```bash
   mysqlimport db1 t1.txt
   ```

   或

   ```sql
   USE db1;
   LOAD DATA INFILE 't1.txt' INTO TABLE t1;
   ```

### 数据格式化选项

如果导出时使用了数据格式化选项（如字段分隔符、引号等），加载时需使用相同选项：

```bash
mysqlimport --fields-terminated-by=, --fields-enclosed-by='"' --lines-terminated-by=0x0d0a db1 t1.txt
```

或

```sql
USE db1;
LOAD DATA INFILE 't1.txt' INTO TABLE t1 
FIELDS TERMINATED BY ',' 
FIELDS ENCLOSED BY '"' 
LINES TERMINATED BY '\r\n';
```

### 对比总结

| **工具**                     | **特点**                                     | **适用场景**           |
| ---------------------------- | -------------------------------------------- | ---------------------- |
| **MySQL Shell 导出**         | 支持并行导出、压缩、进度显示和云功能         | 大规模数据导出、云环境 |
| **`mysqldump` SQL 格式**     | 生成 SQL 语句，便于跨平台迁移和选择性恢复    | 小型数据库、逻辑备份   |
| **`mysqldump` 分隔文本格式** | 生成 `.sql` 和 `.txt` 文件，适合快速导入导出 | 数据导出与导入         |

## 数据库复制与迁移

### 复制数据库

1. **导出数据库**：

   ```bash
   mysqldump db1 > dump.sql
   ```

2. **创建新数据库**：

   ```bash
   mysqladmin create db2
   ```

3. **导入数据**：

   ```bash
   mysql db2 < dump.sql
   ```

- **注意**：不要使用 `--databases` 选项，否则会在导出文件中包含 `USE db1` 语句，覆盖导入时的目标数据库。

## 从一台服务器复制数据库到另一台服务器

### 方法 1：使用 `--databases` 选项

1. **在服务器 1 上导出**：

   ```bash
   mysqldump --databases db1 > dump.sql
   ```

2. **将导出文件复制到服务器 2**。

3. **在服务器 2 上导入**：

   ```bash
   mysql < dump.sql
   ```

### 方法 2：不使用 `--databases` 选项

1. **在服务器 1 上导出**：

   ```bash
   mysqldump db1 > dump.sql
   ```

2. **在服务器 2 上创建数据库**：

   ```bash
   mysqladmin create db1
   ```

3. **在服务器 2 上导入**：

   ```bash
   mysql db1 < dump.sql
   ```

---

## 导出存储程序

### 选项说明

- `--events`：导出事件调度器事件。
- `--routines`：导出存储过程和函数。
- `--triggers`：导出表的触发器（默认启用）。

### 示例

- 导出存储过程和函数：

  ```bash
  mysqldump --routines db1 > dump.sql
  ```

- 导出事件：

  ```bash
  mysqldump --events db1 > dump.sql
  ```

- 禁用触发器导出：

  ```bash
  mysqldump --skip-triggers db1 > dump.sql
  ```

## 分别导出表结构和数据

### 导出表结构

- **命令**：

  ```bash
  mysqldump --no-data test > dump-defs.sql
  ```

- **包含存储程序和事件**：

  ```bash
  mysqldump --no-data --routines --events test > dump-defs.sql
  ```

### 导出表数据

- **命令**：

  ```bash
  mysqldump --no-create-info test > dump-data.sql
  ```

## 使用 `mysqldump` 测试升级兼容性

### 步骤

1. **在生产服务器上导出表结构**：

   ```bash
   mysqldump --all-databases --no-data --routines --events > dump-defs.sql
   ```

2. **在升级后的服务器上导入表结构**：

   ```bash
   mysql < dump-defs.sql
   ```

3. **检查警告或错误**：

   - 确认表结构处理正确。

4. **在生产服务器上导出表数据**：

   ```bash
   mysqldump --all-databases --no-create-info > dump-data.sql
   ```

5. **在升级后的服务器上导入表数据**：

   ```bash
   mysql < dump-data.sql
   ```

6. **验证数据**：

   - 检查表内容并运行测试查询。

### 对比总结

| **操作**               | **命令**                                                     | **用途**                       |
| ---------------------- | ------------------------------------------------------------ | ------------------------------ |
| **复制数据库**         | `mysqldump db1 > dump.sql` + `mysql db2 < dump.sql`          | 在同一服务器上复制数据库       |
| **跨服务器复制数据库** | `mysqldump --databases db1 > dump.sql` + `mysql < dump.sql`  | 从一台服务器复制到另一台服务器 |
| **导出存储程序**       | `mysqldump --routines --events db1 > dump.sql`               | 导出存储过程、函数和事件       |
| **导出表结构**         | `mysqldump --no-data test > dump-defs.sql`                   | 仅导出表结构                   |
| **导出表数据**         | `mysqldump --no-create-info test > dump-data.sql`            | 仅导出表数据                   |
| **测试升级兼容性**     | `mysqldump --all-databases --no-data --routines --events > dump-defs.sql` | 验证升级后的表结构兼容性       |

## 时间点恢复（Point-in-Time Recovery）

### 概述

- **定义**：时间点恢复是指将数据恢复到某个特定时间点的状态。
- **步骤**：
  1. 恢复完整备份，使服务器回到备份时的状态。
  2. 使用二进制日志逐步恢复从备份时间点到目标时间点的数据更改。

## 使用二进制日志进行时间点恢复

### 1. 查看二进制日志

- **查看所有二进制日志文件**：

  ```sql
  SHOW BINARY LOGS;
  ```

- **查看当前二进制日志文件**：

  ```sql
  SHOW MASTER STATUS;
  ```

### 2. 应用二进制日志

- **基本命令**：

  ```bash
  mysqlbinlog binlog_files | mysql -u root -p
  ```

- **处理加密的二进制日志**（MySQL 8.0.14 及以上版本）：

  ```bash
  mysqlbinlog --read-from-remote-server --host=host_name --port=3306 --user=root --password --ssl-mode=required binlog_files | mysql -u root -p
  ```

### 3. 查看和编辑二进制日志

- **查看日志内容**：

  ```bash
  mysqlbinlog binlog_files | more
  ```

- **保存日志内容到文件**：

  ```bash
  mysqlbinlog binlog_files > tmpfile
  ```

- **编辑文件后应用**：

  ```bash
  mysql -u root -p < tmpfile
  ```

### 4. 安全处理多个二进制日志

- **避免问题**：使用单个连接处理所有二进制日志文件。

- **示例**：

  ```bash
  mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p
  ```

- **保存到文件后处理**：

  ```bash
  mysqlbinlog binlog.000001 > /tmp/statements.sql
  mysqlbinlog binlog.000002 >> /tmp/statements.sql
  mysql -u root -p -e "source /tmp/statements.sql"
  ```

- **处理包含 GTIDs 的日志**：

  ```bash
  mysqlbinlog --skip-gtids binlog.000001 > /tmp/dump.sql
  mysqlbinlog --skip-gtids binlog.000002 >> /tmp/dump.sql
  mysql -u root -p -e "source /tmp/dump.sql"
  ```

## 使用事件位置进行时间点恢复

### 示例场景

- **问题**：在 2020 年 3 月 11 日 20:06:00 左右，执行了一条删除表的 SQL 语句。
- **目标**：将数据库恢复到删除表之前的状态。

### 步骤

1. **恢复完整备份**：

   - 恢复到目标时间点之前的完整备份。
   - 记录恢复后的二进制日志位置，并重启服务器。

2. **查找目标时间点的日志位置**：

   - 使用 `mysqlbinlog` 查找目标时间点附近的事件位置。

   - 示例：

     ```bash
     mysqlbinlog --start-datetime="2020-03-11 20:05:00" --stop-datetime="2020-03-11 20:07:00" /var/lib/mysql/bin.123456
     ```

3. **应用二进制日志**：

   - 从恢复后的日志位置（如 155）到目标时间点之前的日志位置（如 232）：

     ```bash
     mysqlbinlog --start-position=155 --stop-position=232 /var/lib/mysql/bin.123456 | mysql -u root -p
     ```

4. **恢复目标时间点之后的数据**：

   - 如果需要恢复目标时间点之后的数据，从目标时间点的日志位置（如 355）开始应用：

     ```bash
     mysqlbinlog --start-position=355 /var/lib/mysql/bin.123456 | mysql -u root -p
     ```

### 对比总结

| **操作**             | **命令**                                                     | **用途**               |
| -------------------- | ------------------------------------------------------------ | ---------------------- |
| **查看二进制日志**   | `SHOW BINARY LOGS;` 或 `SHOW MASTER STATUS;`                 | 获取二进制日志文件信息 |
| **应用二进制日志**   | `mysqlbinlog binlog_files | mysql -u root -p`                | 恢复数据更改           |
| **处理加密日志**     | `mysqlbinlog --read-from-remote-server ...`                  | 读取加密的二进制日志   |
| **编辑日志内容**     | `mysqlbinlog binlog_files > tmpfile` + `mysql -u root -p < tmpfile` | 选择性恢复日志内容     |
| **安全处理多个日志** | `mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p` | 避免临时表问题         |
| **时间点恢复**       | `mysqlbinlog --start-position=155 --stop-position=232 ...`   | 恢复到特定时间点       |





------

# 14-mysql partitioning

## MySQL 8.0 分区支持

### 分区概述

- **支持的存储引擎**：`InnoDB` 和 `NDB`。
- **分区类型**：
  - **水平分区**：将表的不同行分配到不同的物理分区。
  - **垂直分区**：MySQL 8.0 不支持。

## 分区的优势

### 主要优点

1. **存储扩展**：

   - 单个表可以存储超过单个磁盘或文件系统分区的数据。

2. **数据管理**：

   - 通过删除分区轻松移除无用数据。
   - 通过添加新分区简化新数据的插入。

3. **查询优化**：

   - 查询时自动排除不相关的分区。

   - 支持显式分区选择，例如：

     ```sql
     SELECT * FROM t PARTITION (p0, p1) WHERE c < 5;
     ```

   - 支持 `DELETE`、`INSERT`、`REPLACE`、`UPDATE` 和 `LOAD DATA` 等操作的分区选择。

## 分区类型

### 1. **RANGE 分区**

- **定义**：根据列值的范围将行分配到分区。

- **示例**：

  ```sql
  CREATE TABLE members (
      firstname VARCHAR(25) NOT NULL,
      lastname VARCHAR(25) NOT NULL,
      username VARCHAR(16) NOT NULL,
      email VARCHAR(35),
      joined DATE NOT NULL
  )
  PARTITION BY RANGE(YEAR(joined)) (
      PARTITION p0 VALUES LESS THAN (1960),
      PARTITION p1 VALUES LESS THAN (1970),
      PARTITION p2 VALUES LESS THAN (1980),
      PARTITION p3 VALUES LESS THAN (1990),
      PARTITION p4 VALUES LESS THAN MAXVALUE
  );
  ```

### 2. **LIST 分区**

- **定义**：根据列值匹配一组离散值来选择分区。

- **示例**：

  ```sql
  CREATE TABLE members (
      firstname VARCHAR(25) NOT NULL,
      lastname VARCHAR(25) NOT NULL,
      username VARCHAR(16) NOT NULL,
      email VARCHAR(35),
      joined DATE NOT NULL
  )
  PARTITION BY LIST(YEAR(joined)) (
      PARTITION p0 VALUES IN (1960, 1970),
      PARTITION p1 VALUES IN (1980, 1990)
  );
  ```

### 3. **HASH 分区**

- **定义**：根据用户定义的表达式返回值选择分区。

- **示例**：

  ```sql
  CREATE TABLE members (
      firstname VARCHAR(25) NOT NULL,
      lastname VARCHAR(25) NOT NULL,
      username VARCHAR(16) NOT NULL,
      email VARCHAR(35),
      joined DATE NOT NULL
  )
  PARTITION BY HASH(YEAR(joined))
  PARTITIONS 6;
  ```

### 4. **KEY 分区**

- **定义**：类似于 `HASH` 分区，但使用 MySQL 提供的哈希函数。

- **示例**：

  ```sql
  CREATE TABLE members (
      firstname VARCHAR(25) NOT NULL,
      lastname VARCHAR(25) NOT NULL,
      username VARCHAR(16) NOT NULL,
      email VARCHAR(35),
      joined DATE NOT NULL
  )
  PARTITION BY KEY(joined)
  PARTITIONS 6;
  ```

## 分区的常见用途

### 按日期分区

- **场景**：按日期范围分区，便于管理和查询。

- **示例**：

  ```sql
  CREATE TABLE members (
      firstname VARCHAR(25) NOT NULL,
      lastname VARCHAR(25) NOT NULL,
      username VARCHAR(16) NOT NULL,
      email VARCHAR(35),
      joined DATE NOT NULL
  )
  PARTITION BY RANGE(YEAR(joined)) (
      PARTITION p0 VALUES LESS THAN (1960),
      PARTITION p1 VALUES LESS THAN (1970),
      PARTITION p2 VALUES LESS THAN (1980),
      PARTITION p3 VALUES LESS THAN (1990),
      PARTITION p4 VALUES LESS THAN MAXVALUE
  );
  ```

### 对比总结

| **分区类型** | **定义**                           | **适用场景**                 |
| ------------ | ---------------------------------- | ---------------------------- |
| **RANGE**    | 根据列值的范围分配分区             | 按日期、数值范围分区         |
| **LIST**     | 根据列值匹配一组离散值分配分区     | 按离散值（如地区、类别）分区 |
| **HASH**     | 根据用户定义的表达式返回值分配分区 | 均匀分布数据                 |
| **KEY**      | 根据 MySQL 提供的哈希函数分配分区  | 均匀分布数据，支持非整数列   |

## MySQL 分区表：RANGE 分区

### RANGE 分区概述

- **定义**：根据分区表达式的值范围将表的行分配到不同的分区。
- **特点**：
  - 分区范围应连续且不重叠。
  - 使用 `VALUES LESS THAN` 定义分区范围。

## 创建 RANGE 分区表

### 示例 1：按 `store_id` 分区

```sql
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
PARTITION BY RANGE (store_id) (
    PARTITION p0 VALUES LESS THAN (6),
    PARTITION p1 VALUES LESS THAN (11),
    PARTITION p2 VALUES LESS THAN (16),
    PARTITION p3 VALUES LESS THAN (21)
);
```

### 示例 2：按 `store_id` 分区，包含 `MAXVALUE`

```sql
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
PARTITION BY RANGE (store_id) (
    PARTITION p0 VALUES LESS THAN (6),
    PARTITION p1 VALUES LESS THAN (11),
    PARTITION p2 VALUES LESS THAN (16),
    PARTITION p3 VALUES LESS THAN MAXVALUE
);
```

### 示例 3：按 `job_code` 分区

```sql
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
PARTITION BY RANGE (job_code) (
    PARTITION p0 VALUES LESS THAN (100),
    PARTITION p1 VALUES LESS THAN (1000),
    PARTITION p2 VALUES LESS THAN (10000)
);
```

### 示例 4：按 `YEAR(separated)` 分区

```sql
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
PARTITION BY RANGE (YEAR(separated)) (
    PARTITION p0 VALUES LESS THAN (1991),
    PARTITION p1 VALUES LESS THAN (1996),
    PARTITION p2 VALUES LESS THAN (2001),
    PARTITION p3 VALUES LESS THAN MAXVALUE
);
```

### 示例 5：按 `UNIX_TIMESTAMP(report_updated)` 分区

```sql
CREATE TABLE quarterly_report_status (
    report_id INT NOT NULL,
    report_status VARCHAR(20) NOT NULL,
    report_updated TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
)
PARTITION BY RANGE (UNIX_TIMESTAMP(report_updated)) (
    PARTITION p0 VALUES LESS THAN (UNIX_TIMESTAMP('2008-01-01 00:00:00')),
    PARTITION p1 VALUES LESS THAN (UNIX_TIMESTAMP('2008-04-01 00:00:00')),
    PARTITION p2 VALUES LESS THAN (UNIX_TIMESTAMP('2008-07-01 00:00:00')),
    PARTITION p3 VALUES LESS THAN (UNIX_TIMESTAMP('2008-10-01 00:00:00')),
    PARTITION p4 VALUES LESS THAN (UNIX_TIMESTAMP('2009-01-01 00:00:00')),
    PARTITION p5 VALUES LESS THAN (UNIX_TIMESTAMP('2009-04-01 00:00:00')),
    PARTITION p6 VALUES LESS THAN (UNIX_TIMESTAMP('2009-07-01 00:00:00')),
    PARTITION p7 VALUES LESS THAN (UNIX_TIMESTAMP('2009-10-01 00:00:00')),
    PARTITION p8 VALUES LESS THAN (UNIX_TIMESTAMP('2010-01-01 00:00:00')),
    PARTITION p9 VALUES LESS THAN (MAXVALUE)
);
```

### 示例 6：按 `YEAR(joined)` 分区

```sql
CREATE TABLE members (
    firstname VARCHAR(25) NOT NULL,
    lastname VARCHAR(25) NOT NULL,
    username VARCHAR(16) NOT NULL,
    email VARCHAR(35),
    joined DATE NOT NULL
)
PARTITION BY RANGE (YEAR(joined)) (
    PARTITION p0 VALUES LESS THAN (1960),
    PARTITION p1 VALUES LESS THAN (1970),
    PARTITION p2 VALUES LESS THAN (1980),
    PARTITION p3 VALUES LESS THAN (1990),
    PARTITION p4 VALUES LESS THAN MAXVALUE
);
```

### 示例 7：按 `RANGE COLUMNS(joined)` 分区

```sql
CREATE TABLE members (
    firstname VARCHAR(25) NOT NULL,
    lastname VARCHAR(25) NOT NULL,
    username VARCHAR(16) NOT NULL,
    email VARCHAR(35),
    joined DATE NOT NULL
)
PARTITION BY RANGE COLUMNS(joined) (
    PARTITION p0 VALUES LESS THAN ('1960-01-01'),
    PARTITION p1 VALUES LESS THAN ('1970-01-01'),
    PARTITION p2 VALUES LESS THAN ('1980-01-01'),
    PARTITION p3 VALUES LESS THAN ('1990-01-01'),
    PARTITION p4 VALUES LESS THAN MAXVALUE
);
```

### 对比总结

| **分区方式**      | **定义**                         | **适用场景**           |
| ----------------- | -------------------------------- | ---------------------- |
| **RANGE**         | 根据列值的范围分配分区           | 按数值、日期范围分区   |
| **RANGE COLUMNS** | 根据列值的范围分配分区，支持多列 | 按多列范围分区         |
| **MAXVALUE**      | 用于定义最后一个分区的上限       | 处理超出定义范围的数据 |

## MySQL 分区表：LIST 分区

### LIST 分区概述

- **定义**：根据列值是否属于一组离散值列表来选择分区。
- **特点**：
  - 每个分区对应一组特定的列值。
  - 不支持类似 `MAXVALUE` 的“兜底”分区，所有可能的值必须显式定义。

## 创建 LIST 分区表

### 示例 1：按 `store_id` 分区

```sql
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT,
    store_id INT
)
PARTITION BY LIST(store_id) (
    PARTITION pNorth VALUES IN (3, 5, 6, 9, 17),
    PARTITION pEast VALUES IN (1, 2, 10, 11, 19, 20),
    PARTITION pWest VALUES IN (4, 12, 13, 14, 18),
    PARTITION pCentral VALUES IN (7, 8, 15, 16)
);
```

### 示例 2：按 `c1` 分区

```sql
CREATE TABLE h2 (
    c1 INT,
    c2 INT
)
PARTITION BY LIST(c1) (
    PARTITION p0 VALUES IN (1, 4, 7),
    PARTITION p1 VALUES IN (2, 5, 8)
);
```

## LIST 分区的注意事项

### 1. **未定义值的处理**

- 如果插入的值未在分区定义中列出，MySQL 会抛出错误。

- **示例**：

  ```sql
  INSERT INTO h2 VALUES (3, 5);
  ```

  **错误**：

  ```
  ERROR 1525 (HY000): Table has no partition for value 3
  ```

### 2. **使用 `IGNORE` 忽略错误**

- 使用 `INSERT IGNORE` 可以忽略未定义值的错误。

- **示例**：

  ```sql
  INSERT IGNORE INTO h2 VALUES (2, 5), (6, 10), (7, 5), (3, 1), (1, 9);
  ```

  **结果**：

  - 成功插入 `(2, 5)`、`(7, 5)` 和 `(1, 9)`。
  - 忽略 `(6, 10)` 和 `(3, 1)`。

### 对比总结

| **分区方式** | **定义**                                 | **适用场景**                 |
| ------------ | ---------------------------------------- | ---------------------------- |
| **LIST**     | 根据列值是否属于一组离散值列表来选择分区 | 按离散值（如地区、类别）分区 |
| **RANGE**    | 根据列值的范围分配分区                   | 按数值、日期范围分区         |
| **MAXVALUE** | 用于定义最后一个分区的上限               | 处理超出定义范围的数据       |

## MySQL 分区表：COLUMNS 分区

### COLUMNS 分区概述

- **定义**：`COLUMNS` 分区是 `RANGE` 和 `LIST` 分区的变体，支持使用多列作为分区键。
- **特点**：
  - 支持非整数列（如 `DATE`、`DATETIME`、`CHAR`、`VARCHAR` 等）。
  - 分区键的列值用于确定行的存储位置和分区修剪。

## RANGE COLUMNS 分区

### 特点

- **与 RANGE 分区的区别**：
  - 不接受表达式，仅接受列名。
  - 支持多列分区键。
  - 基于列值的元组比较，而非标量值比较。
  - 支持字符串、`DATE` 和 `DATETIME` 列作为分区键。

### 语法

```sql
CREATE TABLE table_name
PARTITION BY RANGE COLUMNS(column_list) (
    PARTITION partition_name VALUES LESS THAN (value_list)[,
    PARTITION partition_name VALUES LESS THAN (value_list)][,
    ...]
);
```

### 示例 1：按多列分区

```sql
CREATE TABLE rcx (
    a INT,
    b INT,
    c CHAR(3),
    d INT
)
PARTITION BY RANGE COLUMNS(a, d, c) (
    PARTITION p0 VALUES LESS THAN (5, 10, 'ggg'),
    PARTITION p1 VALUES LESS THAN (10, 20, 'mmm'),
    PARTITION p2 VALUES LESS THAN (15, 30, 'sss'),
    PARTITION p3 VALUES LESS THAN (MAXVALUE, MAXVALUE, MAXVALUE)
);
```

### 示例 2：按单列分区

```sql
CREATE TABLE rx (
    a INT,
    b INT
)
PARTITION BY RANGE COLUMNS(a) (
    PARTITION p0 VALUES LESS THAN (5),
    PARTITION p1 VALUES LESS THAN (MAXVALUE)
);
```

### 示例 3：按 `lname` 列分区

```sql
CREATE TABLE employees_by_lname (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
PARTITION BY RANGE COLUMNS(lname) (
    PARTITION p0 VALUES LESS THAN ('g'),
    PARTITION p1 VALUES LESS THAN ('m'),
    PARTITION p2 VALUES LESS THAN ('t'),
    PARTITION p3 VALUES LESS THAN (MAXVALUE)
);
```

### 示例 4：按 `hired` 列分区

```sql
ALTER TABLE employees
PARTITION BY RANGE COLUMNS(hired) (
    PARTITION p0 VALUES LESS THAN ('1970-01-01'),
    PARTITION p1 VALUES LESS THAN ('1980-01-01'),
    PARTITION p2 VALUES LESS THAN ('1990-01-01'),
    PARTITION p3 VALUES LESS THAN ('2000-01-01'),
    PARTITION p4 VALUES LESS THAN ('2010-01-01'),
    PARTITION p5 VALUES LESS THAN (MAXVALUE)
);
```

---

## LIST COLUMNS 分区

### 特点

- **定义**：`LIST COLUMNS` 分区是 `LIST` 分区的变体，支持使用多列作为分区键。
- **适用场景**：按离散值（如城市、日期）分区。

### 示例 1：按 `city` 列分区

```sql
CREATE TABLE customers_1 (
    first_name VARCHAR(25),
    last_name VARCHAR(25),
    street_1 VARCHAR(30),
    street_2 VARCHAR(30),
    city VARCHAR(15),
    renewal DATE
)
PARTITION BY LIST COLUMNS(city) (
    PARTITION pRegion_1 VALUES IN('Oskarshamn', 'Högsby', 'Mönsterås'),
    PARTITION pRegion_2 VALUES IN('Vimmerby', 'Hultsfred', 'Västervik'),
    PARTITION pRegion_3 VALUES IN('Nässjö', 'Eksjö', 'Vetlanda'),
    PARTITION pRegion_4 VALUES IN('Uppvidinge', 'Alvesta', 'Växjo')
);
```

### 示例 2：按 `renewal` 列分区

```sql
CREATE TABLE customers_1 (
    first_name VARCHAR(25),
    last_name VARCHAR(25),
    street_1 VARCHAR(30),
    street_2 VARCHAR(30),
    city VARCHAR(15),
    renewal DATE
)
PARTITION BY LIST COLUMNS(renewal) (
    PARTITION pWeek_1 VALUES IN('2010-02-01', '2010-02-02', '2010-02-03',
                               '2010-02-04', '2010-02-05', '2010-02-06', '2010-02-07'),
    PARTITION pWeek_2 VALUES IN('2010-02-08', '2010-02-09', '2010-02-10',
                               '2010-02-11', '2010-02-12', '2010-02-13', '2010-02-14'),
    PARTITION pWeek_3 VALUES IN('2010-02-15', '2010-02-16', '2010-02-17',
                               '2010-02-18', '2010-02-19', '2010-02-20', '2010-02-21'),
    PARTITION pWeek_4 VALUES IN('2010-02-22', '2010-02-23', '2010-02-24',
                               '2010-02-25', '2010-02-26', '2010-02-27', '2010-02-28')
);
```

### 对比总结

| **分区方式**      | **定义**                                   | **适用场景**                 |
| ----------------- | ------------------------------------------ | ---------------------------- |
| **RANGE COLUMNS** | 根据多列值的范围分配分区                   | 按多列范围分区               |
| **LIST COLUMNS**  | 根据多列值是否属于一组离散值列表来选择分区 | 按离散值（如城市、日期）分区 |
| **MAXVALUE**      | 用于定义最后一个分区的上限                 | 处理超出定义范围的数据       |

## MySQL 分区技术

### HASH 分区

HASH 分区主要用于确保数据在预定义的分区中均匀分布。通过使用 HASH 函数对某一列的值进行计算，MySQL 将数据分配到不同的分区中。

#### 示例

```sql
CREATE TABLE employees (
    id INT NOT NULL, 
    fname VARCHAR(30), 
    lname VARCHAR(30), 
    hired DATE NOT NULL DEFAULT '1970-01-01', 
    separated DATE NOT NULL DEFAULT '9999-12-31', 
    job_code INT, 
    store_id INT 
) 
PARTITION BY HASH(store_id) 
PARTITIONS 4;
```

#### 使用表达式进行 HASH 分区

```sql
CREATE TABLE employees (
    id INT NOT NULL, 
    fname VARCHAR(30), 
    lname VARCHAR(30), 
    hired DATE NOT NULL DEFAULT '1970-01-01', 
    separated DATE NOT NULL DEFAULT '9999-12-31', 
    job_code INT, 
    store_id INT 
) 
PARTITION BY HASH(YEAR(hired)) 
PARTITIONS 4;
```

### 线性 HASH 分区

线性 HASH 分区与普通 HASH 分区的区别在于，线性 HASH 使用线性二次幂算法，而普通 HASH 使用取模运算。

#### 示例

```sql
CREATE TABLE employees (
    id INT NOT NULL, 
    fname VARCHAR(30), 
    lname VARCHAR(30), 
    hired DATE NOT NULL DEFAULT '1970-01-01', 
    separated DATE NOT NULL DEFAULT '9999-12-31', 
    job_code INT, 
    store_id INT 
) 
PARTITION BY LINEAR HASH(YEAR(hired)) 
PARTITIONS 4;
```

#### 线性 HASH 分区算法

给定表达式 `expr`，线性 HASH 分区将记录存储在分区号 `N` 中，`N` 的计算步骤如下：

1. 找到大于分区数 `num` 的下一个 2 的幂，记为 `V`。

   ```sql
   V = POWER(2, CEILING(LOG(2, num)))
   ```

2. 计算 `N = F(column_list) & (V - 1)`。

3. 如果 `N >= num`，则：

   - 设置 `V = V / 2`
   - 设置 `N = N & (V - 1)`

#### 示例计算

```sql
CREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATE) 
PARTITION BY LINEAR HASH( YEAR(col3) ) 
PARTITIONS 6;

-- 示例 1
V = POWER(2, CEILING( LOG(2,6) )) = 8 
N = YEAR('2003-04-14') & (8 - 1) 
    = 2003 & 7 
    = 3 
-- 3 >= 6 为 FALSE，记录存储在分区 #3

-- 示例 2
V = 8 
N = YEAR('1998-10-19') & (8 - 1) 
    = 1998 & 7 
    = 6 
-- 6 >= 6 为 TRUE，需要进一步计算
N = 6 & ((8 / 2) - 1) 
    = 6 & 3 
    = 2 
-- 2 >= 6 为 FALSE，记录存储在分区 #2
```

### KEY 分区

KEY 分区与 HASH 分区类似，区别在于 KEY 分区的哈希函数由 MySQL 服务器提供，而不是用户定义的表达式。

#### 示例

```sql
CREATE TABLE k1 (
    id INT NOT NULL PRIMARY KEY, 
    name VARCHAR(20) 
) 
PARTITION BY KEY() 
PARTITIONS 2;
```

#### 线性 KEY 分区

```sql
CREATE TABLE tk ( col1 INT NOT NULL, col2 CHAR(5), col3 DATE ) 
PARTITION BY LINEAR KEY (col1) 
PARTITIONS 3;
```

### 复合分区（子分区）

复合分区（子分区）是对分区表中的每个分区进行进一步划分。

#### 示例

```sql
CREATE TABLE ts (id INT, purchased DATE) 
    PARTITION BY RANGE( YEAR(purchased) ) 
    SUBPARTITION BY HASH( TO_DAYS(purchased) ) 
    SUBPARTITIONS 2 ( 
        PARTITION p0 VALUES LESS THAN (1990), 
        PARTITION p1 VALUES LESS THAN (2000), 
        PARTITION p2 VALUES LESS THAN MAXVALUE 
    );
```

#### 显式定义子分区

```sql
CREATE TABLE ts (id INT, purchased DATE) 
PARTITION BY RANGE( YEAR(purchased) ) 
SUBPARTITION BY HASH( TO_DAYS(purchased) ) ( 
    PARTITION p0 VALUES LESS THAN (1990) ( 
        SUBPARTITION s0, 
        SUBPARTITION s1 
    ), 
    PARTITION p1 VALUES LESS THAN (2000) ( 
        SUBPARTITION s2, 
        SUBPARTITION s3 
    ), 
    PARTITION p2 VALUES LESS THAN MAXVALUE ( 
        SUBPARTITION s4, 
        SUBPARTITION s5 
    ) 
);
```

### 总结

- **HASH 分区**：通过哈希函数均匀分布数据。
- **线性 HASH 分区**：使用线性二次幂算法进行分区。
- **KEY 分区**：由 MySQL 提供哈希函数。
- **复合分区**：对分区进一步划分，支持更细粒度的数据管理。

## MySQL 分区中的 NULL 值处理

MySQL 分区表在处理 `NULL` 值时，行为因分区类型的不同而有所差异。以下是针对不同分区类型的 `NULL` 值处理方式。

---

### RANGE 分区中的 NULL 值处理

在 RANGE 分区中，如果插入的行的分区列值为 `NULL`，则该行会被插入到最低的分区中。

#### 示例

```sql
CREATE TABLE t1 (
    c1 INT,
    c2 VARCHAR(20)
)
PARTITION BY RANGE(c1) (
    PARTITION p0 VALUES LESS THAN (0),
    PARTITION p1 VALUES LESS THAN (10),
    PARTITION p2 VALUES LESS THAN MAXVALUE
);

CREATE TABLE t2 (
    c1 INT,
    c2 VARCHAR(20)
)
PARTITION BY RANGE(c1) (
    PARTITION p0 VALUES LESS THAN (-5),
    PARTITION p1 VALUES LESS THAN (0),
    PARTITION p2 VALUES LESS THAN (10),
    PARTITION p3 VALUES LESS THAN MAXVALUE
);
```

#### 插入 NULL 值

```sql
INSERT INTO t1 VALUES (NULL, 'mothra');
INSERT INTO t2 VALUES (NULL, 'mothra');
```

#### 查询分区信息

```sql
SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
FROM INFORMATION_SCHEMA.PARTITIONS
WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME LIKE 't_';
```

#### 结果

- `t1` 和 `t2` 中的 `NULL` 值都被插入到最低的分区（`p0`）。
- 删除分区 `p0` 后，`NULL` 值也会被删除。

---

### LIST 分区中的 NULL 值处理

在 LIST 分区中，只有明确为 `NULL` 值定义了分区时，才能插入 `NULL` 值。

#### 示例

```sql
CREATE TABLE ts1 (
    c1 INT,
    c2 VARCHAR(20)
)
PARTITION BY LIST(c1) (
    PARTITION p0 VALUES IN (0, 3, 6),
    PARTITION p1 VALUES IN (1, 4, 7),
    PARTITION p2 VALUES IN (2, 5, 8)
);

-- 插入 NULL 值会失败
INSERT INTO ts1 VALUES (NULL, 'mothra'); -- 报错：Table has no partition for value NULL
```

#### 允许 NULL 值的 LIST 分区

```sql
CREATE TABLE ts2 (
    c1 INT,
    c2 VARCHAR(20)
)
PARTITION BY LIST(c1) (
    PARTITION p0 VALUES IN (0, 3, 6),
    PARTITION p1 VALUES IN (1, 4, 7),
    PARTITION p2 VALUES IN (2, 5, 8),
    PARTITION p3 VALUES IN (NULL)
);

CREATE TABLE ts3 (
    c1 INT,
    c2 VARCHAR(20)
)
PARTITION BY LIST(c1) (
    PARTITION p0 VALUES IN (0, 3, 6),
    PARTITION p1 VALUES IN (1, 4, 7, NULL),
    PARTITION p2 VALUES IN (2, 5, 8)
);
```

#### 插入 NULL 值

```sql
INSERT INTO ts2 VALUES (NULL, 'mothra'); -- 成功插入到 p3
INSERT INTO ts3 VALUES (NULL, 'mothra'); -- 成功插入到 p1
```

#### 查询分区信息

```sql
SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
FROM INFORMATION_SCHEMA.PARTITIONS
WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME LIKE 't_';
```

---

### HASH 和 KEY 分区中的 NULL 值处理

在 HASH 和 KEY 分区中，任何产生 `NULL` 值的分区表达式都会被当作 `0` 处理。

#### 示例

```sql
CREATE TABLE th (
    c1 INT,
    c2 VARCHAR(20)
)
PARTITION BY HASH(c1)
PARTITIONS 2;
```

#### 插入 NULL 值

```sql
INSERT INTO th VALUES (NULL, 'mothra'), (0, 'gigan');
```

#### 查询分区信息

```sql
SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
FROM INFORMATION_SCHEMA.PARTITIONS
WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME = 'th';
```

#### 结果

- `NULL` 值被当作 `0` 处理，插入到分区 `p0`。
- 分区 `p0` 包含两行数据（`NULL` 和 `0`）。

### 总结

- **RANGE 分区**：`NULL` 值插入到最低分区。
- **LIST 分区**：必须显式定义 `NULL` 值分区，否则插入 `NULL` 值会失败。
- **HASH 和 KEY 分区**：`NULL` 值被当作 `0` 处理。

通过合理设计分区策略，可以有效管理包含 `NULL` 值的数据。

## MySQL 分区表操作详解

以下是对 MySQL 分区表操作的详细说明和示例，涵盖创建分区表、插入数据、查询分区、删除分区、添加分区以及重组分区等操作。

### 创建分区表

使用 `RANGE` 分区，按 `YEAR(purchased)` 分区。

```sql
CREATE TABLE tr (
    id INT,
    name VARCHAR(50),
    purchased DATE
)
PARTITION BY RANGE( YEAR(purchased) ) (
    PARTITION p0 VALUES LESS THAN (1990),
    PARTITION p1 VALUES LESS THAN (1995),
    PARTITION p2 VALUES LESS THAN (2000),
    PARTITION p3 VALUES LESS THAN (2005),
    PARTITION p4 VALUES LESS THAN (2010),
    PARTITION p5 VALUES LESS THAN (2015)
);
```

---

### 插入数据

向分区表中插入数据。

```sql
INSERT INTO tr VALUES
(1, 'desk organiser', '2003-10-15'),
(2, 'alarm clock', '1997-11-05'),
(3, 'chair', '2009-03-10'),
(4, 'bookcase', '1989-01-10'),
(5, 'exercise bike', '2014-05-09'),
(6, 'sofa', '1987-06-05'),
(7, 'espresso maker', '2011-11-22'),
(8, 'aquarium', '1992-08-04'),
(9, 'study desk', '2006-09-16'),
(10, 'lava lamp', '1998-12-25');
```

---

### 查询分区数据

#### 查询特定时间范围内的数据

```sql
SELECT * FROM tr
WHERE purchased BETWEEN '1995-01-01' AND '1999-12-31';
```

#### 结果

```plaintext
+------+--------------+------------+
| id   | name         | purchased  |
+------+--------------+------------+
| 2    | alarm clock  | 1997-11-05 |
| 10   | lava lamp    | 1998-12-25 |
+------+--------------+------------+
```

#### 查询特定分区的数据

```sql
SELECT * FROM tr PARTITION (p2);
```

#### 结果

```plaintext
+------+--------------+------------+
| id   | name         | purchased  |
+------+--------------+------------+
| 2    | alarm clock  | 1997-11-05 |
| 10   | lava lamp    | 1998-12-25 |
+------+--------------+------------+
```

---

### 删除分区

删除分区 `p2`。

```sql
ALTER TABLE tr DROP PARTITION p2;
```

#### 验证删除分区后的查询

```sql
SELECT * FROM tr
WHERE purchased BETWEEN '1995-01-01' AND '1999-12-31';
```

#### 结果

```plaintext
Empty set (0.00 sec)
```

---

### 查看表结构

查看分区表的结构。

```sql
SHOW CREATE TABLE tr\G
```

#### 结果

```plaintext
*************************** 1. row ***************************
       Table: tr
Create Table: CREATE TABLE `tr` (
  `id` int(11) DEFAULT NULL,
  `name` varchar(50) DEFAULT NULL,
  `purchased` date DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1
/*!50100 PARTITION BY RANGE ( YEAR(purchased))
(PARTITION p0 VALUES LESS THAN (1990) ENGINE = InnoDB,
 PARTITION p1 VALUES LESS THAN (1995) ENGINE = InnoDB,
 PARTITION p3 VALUES LESS THAN (2005) ENGINE = InnoDB,
 PARTITION p4 VALUES LESS THAN (2010) ENGINE = InnoDB,
 PARTITION p5 VALUES LESS THAN (2015) ENGINE = InnoDB) */
```

---

### 插入新数据并查询

插入新数据并查询特定时间范围内的数据。

```sql
INSERT INTO tr VALUES (11, 'pencil holder', '1995-07-12');
SELECT * FROM tr
WHERE purchased BETWEEN '1995-01-01' AND '2004-12-31';
```

#### 结果

```plaintext
+-----+----------------+------------+
| id  | name           | purchased  |
+-----+----------------+------------+
| 1   | desk organizer | 2003-10-15 |
| 11  | pencil holder  | 1995-07-12 |
+-----+----------------+------------+
```

---

### 删除分区并验证

删除分区 `p3` 并验证查询结果。

```sql
ALTER TABLE tr DROP PARTITION p3;
SELECT * FROM tr
WHERE purchased BETWEEN '1995-01-01' AND '2004-12-31';
```

#### 结果

```plaintext
Empty set (0.00 sec)
```

---

### 添加分区

向分区表中添加新分区。

```sql
CREATE TABLE members (
    id INT,
    fname VARCHAR(25),
    lname VARCHAR(25),
    dob DATE
)
PARTITION BY RANGE( YEAR(dob) ) (
    PARTITION p0 VALUES LESS THAN (1980),
    PARTITION p1 VALUES LESS THAN (1990),
    PARTITION p2 VALUES LESS THAN (2000)
);

ALTER TABLE members ADD PARTITION (PARTITION p3 VALUES LESS THAN (2010));
```

---

### 重组分区

重组分区以调整分区范围。

```sql
ALTER TABLE members REORGANIZE PARTITION p0 INTO (
    PARTITION n0 VALUES LESS THAN (1970),
    PARTITION n1 VALUES LESS THAN (1980)
);
```

---

### 错误处理

#### 添加分区时值必须严格递增

```sql
ALTER TABLE members ADD PARTITION (PARTITION n VALUES LESS THAN (1970));
-- 错误：VALUES LESS THAN value must be strictly increasing for each partition
```

#### LIST 分区中常量重复定义

```sql
ALTER TABLE tt ADD PARTITION (PARTITION np VALUES IN (4, 8, 12));
-- 错误：Multiple definition of same constant in list partitioning
```

---

### 总结

- **创建分区表**：使用 `RANGE` 或 `LIST` 分区。
- **插入数据**：数据会根据分区规则自动分配到对应的分区。
- **查询分区数据**：可以直接查询特定分区或按条件查询。
- **删除分区**：使用 `DROP PARTITION` 删除分区及其数据。
- **添加分区**：使用 `ADD PARTITION` 扩展分区范围。
- **重组分区**：使用 `REORGANIZE PARTITION` 调整分区范围或合并分区。

通过合理使用分区表，可以提高查询性能并简化数据管理。

## MySQL 分区表操作笔记

### 分区表的基本操作

#### 创建分区表

```sql
CREATE TABLE clients (
    id INT, 
    fname VARCHAR(30), 
    lname VARCHAR(30), 
    signed DATE 
) 
PARTITION BY HASH( MONTH(signed) ) 
PARTITIONS 12;
```

#### 合并分区

对于使用 `HASH` 或 `KEY` 分区的表，不能直接删除分区，但可以通过 `ALTER TABLE ... COALESCE PARTITION` 合并分区。

```sql
ALTER TABLE clients COALESCE PARTITION 4;
```

- 合并分区时，不能删除所有分区，否则会报错：

```sql
ERROR 1478 (HY000): Cannot remove all partitions, use DROP TABLE instead
```

#### 添加分区

```sql
ALTER TABLE clients ADD PARTITION PARTITIONS 6;
```

### 分区表与普通表的交换

在 MySQL 8.0 中，可以使用 `ALTER TABLE ... EXCHANGE PARTITION` 将分区表的分区与普通表进行交换。

#### 创建分区表

```sql
CREATE TABLE e (
    id INT NOT NULL, 
    fname VARCHAR(30), 
    lname VARCHAR(30) 
) 
PARTITION BY RANGE (id) ( 
    PARTITION p0 VALUES LESS THAN (50), 
    PARTITION p1 VALUES LESS THAN (100), 
    PARTITION p2 VALUES LESS THAN (150), 
    PARTITION p3 VALUES LESS THAN (MAXVALUE) 
);
```

#### 插入数据

```sql
INSERT INTO e VALUES 
    (1669, "Jim", "Smith"), 
    (337, "Mary", "Jones"), 
    (16, "Frank", "White"), 
    (2005, "Linda", "Black");
```

#### 创建普通表并移除分区

```sql
CREATE TABLE e2 LIKE e;
ALTER TABLE e2 REMOVE PARTITIONING;
```

#### 交换分区

```sql
ALTER TABLE e EXCHANGE PARTITION p0 WITH TABLE e2;
```

#### 查询分区信息

```sql
SELECT PARTITION_NAME, TABLE_ROWS 
FROM INFORMATION_SCHEMA.PARTITIONS 
WHERE TABLE_NAME = 'e';
```

#### 查询普通表数据

```sql
SELECT * FROM e2;
```

### 非匹配行的处理

如果普通表中存在不符合分区定义的行，交换分区时会报错。可以通过 `WITHOUT VALIDATION` 忽略验证。

```sql
INSERT INTO e2 VALUES (51, "Ellen", "McDonald");
ALTER TABLE e EXCHANGE PARTITION p0 WITH TABLE e2;
-- 报错：ERROR 1707 (HY000): Found row that does not match the partition

ALTER TABLE e EXCHANGE PARTITION p0 WITH TABLE e2 WITHOUT VALIDATION;
```

### 分区维护操作

#### 重建分区

```sql
ALTER TABLE t1 REBUILD PARTITION p0, p1;
```

#### 优化分区

```sql
ALTER TABLE t1 OPTIMIZE PARTITION p0, p1;
```

#### 分析分区

```sql
ALTER TABLE t1 ANALYZE PARTITION p3;
```

#### 修复分区

```sql
ALTER TABLE t1 REPAIR PARTITION p0,p1;
```

#### 检查分区

```sql
ALTER TABLE trb3 CHECK PARTITION p1;
```

### 分区修剪与选择

#### 分区修剪

分区修剪是自动进行的，查询时只检查相关的分区。

```sql
CREATE TABLE t1 (
    fname VARCHAR(50) NOT NULL, 
    lname VARCHAR(50) NOT NULL, 
    region_code TINYINT UNSIGNED NOT NULL, 
    dob DATE NOT NULL 
) 
PARTITION BY RANGE( region_code ) ( 
    PARTITION p0 VALUES LESS THAN (64), 
    PARTITION p1 VALUES LESS THAN (128), 
    PARTITION p2 VALUES LESS THAN (192), 
    PARTITION p3 VALUES LESS THAN MAXVALUE 
);

SELECT fname, lname, region_code, dob 
FROM t1 
WHERE region_code > 125 AND region_code < 130;
```

#### 分区选择

分区选择与分区修剪类似，但需要手动指定要检查的分区。支持以下 SQL 语句：

- `SELECT`
- `DELETE`
- `INSERT`
- `REPLACE`
- `UPDATE`
- `LOAD DATA`
- `LOAD XML`





------

# 15-NoSQL & MongoDB

## 关系型数据库（如 MySQL）的局限性

- **数据量限制**：
  - 当数据量超过 1000 万条记录时，性能会急剧下降。
  - 原因是关系型数据库使用 B 树索引，随机 I/O 操作会导致性能瓶颈。
  - 即使通过分区（Partition）将数据分布到不同存储位置，也无法彻底解决问题。
  - 例如，MySQL 的分区功能可以将数据按范围或哈希分布到不同表中，但查询时仍需要扫描多个分区，性能提升有限。
- **结构化数据限制**：
  - 关系型数据库只能处理结构化数据（如固定字段的表）。
  - 无法有效处理非结构化数据（如文本、图片、音频、视频等）。
  - 例如，搜索引擎中的大段文本无法拆解成固定字段的表结构。
  - 如果强行将非结构化数据存储到关系型数据库中，会导致表结构复杂、查询效率低下。
- **扩展性问题**：
  - 关系型数据库难以线性扩展，无法通过增加服务器数量来线性提升性能。
  - 例如，一台服务器能处理 100 个并发用户，但两台服务器未必能处理 200 个。
  - 这是因为关系型数据库的 ACID 特性（原子性、一致性、隔离性、持久性）限制了其扩展性。
- **锁机制**：
  - 关系型数据库的锁机制在高并发场景下会成为性能瓶颈。
  - 例如，频繁的写操作会导致锁竞争，降低性能。
  - 即使使用行级锁或乐观锁，也无法完全避免锁冲突。

## 非关系型数据库（NoSQL）的优势

- **处理非结构化数据**：
  - NoSQL 数据库（如 MongoDB）可以处理非结构化或半结构化数据（如 JSON 格式的文档）。
  - 例如，搜索引擎中的大段文本可以直接存储为文档，无需拆解成固定字段。
  - 这种灵活性使得 NoSQL 数据库在处理复杂数据结构时更具优势。
- **高扩展性**：
  - NoSQL 数据库支持分布式存储，能够线性扩展。
  - 例如，通过分片（Sharding）将数据分布到多台服务器上。
  - 这种设计使得 NoSQL 数据库能够轻松应对数据量的增长。
- **弱化锁机制**：
  - 由于数据通常是只写一次、多次读取，锁机制被弱化，性能更高。
  - 例如，日志系统中的数据写入后很少修改，锁竞争减少。
  - 这种设计使得 NoSQL 数据库在高并发场景下表现更佳。
- **动态 Schema**：
  - NoSQL 数据库支持动态 Schema，允许同一集合（Collection）中的文档具有不同的结构。
  - 例如，一个集合中的文档可以有不同的字段。
  - 这种灵活性使得 NoSQL 数据库在处理数据结构频繁变化的场景时更具优势。

## MongoDB

- **MongoDB 的适用场景**：
  - 非结构化数据存储。
  - 高并发读写场景。
  - 数据结构频繁变化的场景。
- **MongoDB 的局限性**：
  - 不支持复杂的事务处理。
  - 不适合强一致性要求的场景。

### MongoDB 的特点

- **文档型数据库**：
  - MongoDB 是一种文档型数据库，数据以 JSON 格式存储。
  - 例如，一个文档可以包含多个键值对（Key-Value）。
  - 这种存储方式使得 MongoDB 在处理复杂数据结构时更加灵活。
- **高性能**：
  - 支持复杂索引（如 2D 地理空间索引），查询性能高。
  - 例如，可以通过地理空间索引快速查找附近的点。
  - 这种高性能使得 MongoDB 在实时查询场景中表现优异。
- **高可用性**：
  - 通过副本集（Replica Set）实现高可用性。
  - 例如，主节点负责写操作，从节点负责读操作。
  - 这种设计使得 MongoDB 在主节点故障时能够快速切换到从节点，保证系统的高可用性。
- **自动分片（Auto-Sharding）**：
  - 支持自动分片，将数据分布到多台服务器上，实现负载均衡。
  - 例如，数据按 ID 范围分布到不同的分片服务器上。
  - 这种设计使得 MongoDB 能够轻松应对数据量的增长。
- **灵活查询**：
  - 支持丰富的查询语言，支持聚合操作（如 MapReduce、Pipeline）。
  - 例如，可以通过聚合管道对数据进行分组、排序、统计。
  - 这种灵活性使得 MongoDB 在处理复杂查询时更加高效。

### MongoDB 的核心概念

- **文档（Document）**：
  - MongoDB 中的基本数据单元，类似于关系型数据库中的一行记录，存储为 JSON 格式。
  - 例如，一个文档可以包含多个键值对（Key-Value）。
  - 文档的结构可以动态变化，无需预先定义 Schema。
- **集合（Collection）**：
  - 类似于关系型数据库中的表，但集合中的文档可以有不同的结构（Schema-Free）。
  - 例如，一个集合中的文档可以有不同的字段。
  - 这种设计使得 MongoDB 在处理数据结构频繁变化的场景时更加灵活。
- **数据库（Database）**：
  - 多个集合的集合，用于组织数据。
  - 例如，一个数据库可以包含多个集合。
  - 这种设计使得 MongoDB 能够更好地组织和管理数据。
- **主键（_id）**：
  - 每个文档都有一个唯一的主键（_id），默认自动生成。
  - 例如，主键用于唯一标识一个文档。
  - 这种设计使得 MongoDB 能够快速定位和查询文档。

###  MongoDB 的索引

- **默认索引**：
  - 每个集合默认在 _id 字段上创建索引。
  - 例如，主键索引用于快速查找文档。
  - 这种设计使得 MongoDB 在查询主键时能够快速定位文档。
- **复杂索引**：
  - 支持 2D 地理空间索引，用于处理地理位置相关的查询。
  - 例如，可以通过地理空间索引查找附近的点。
  - 这种设计使得 MongoDB 在处理地理位置相关的查询时更加高效。
- **索引性能**：
  - 索引可以显著提升查询性能，但会增加写入开销。
  - 例如，频繁的写操作会导致索引更新，降低性能。
  - 这种设计使得 MongoDB 在写入频繁的场景中需要权衡索引的使用。

###  MongoDB 的分片与集群

- **分片（Sharding）**：
  - 将数据分布到多台服务器上，支持水平扩展。
  - 例如，数据按 ID 范围分布到不同的分片服务器上。
  - 这种设计使得 MongoDB 能够轻松应对数据量的增长。
- **副本集（Replica Set）**：
  - 通过主从复制实现高可用性，主节点负责写操作，从节点负责读操作。
  - 例如，主节点故障时，从节点可以接管写操作。
  - 这种设计使得 MongoDB 在主节点故障时能够快速切换到从节点，保证系统的高可用性。
- **Config Server**：
  - 存储分片信息，用于定位数据所在的服务器。
  - 例如，查询请求会先到 Config Server 确定数据位置。
  - 这种设计使得 MongoDB 在分布式环境中能够快速定位数据。

### MongoDB 的查询与操作

- **插入数据**：
  - 使用 `insertOne` 或 `insertMany` 插入文档。
  - 例如，插入一个包含多个键值对的文档。
  - 这种操作使得 MongoDB 能够快速插入数据。
- **查询数据**：
  - 使用 `find` 方法查询文档，支持条件过滤（如 `$gt`、`$lt`、`$in` 等）。
  - 例如，查找评分大于 8 的电影。
  - 这种操作使得 MongoDB 能够快速查询数据。
- **更新数据**：
  - 使用 `updateOne` 或 `updateMany` 更新文档，支持 `$set` 操作符。
  - 例如，更新电影的评分。
  - 这种操作使得 MongoDB 能够快速更新数据。
- **删除数据**：
  - 使用 `deleteOne` 或 `deleteMany` 删除文档。
  - 例如，删除评分低于 5 的电影。
  - 这种操作使得 MongoDB 能够快速删除数据。
- **聚合操作**：
  - 使用聚合管道（Aggregation Pipeline）进行复杂的数据处理，如分组、排序、统计等。
  - 例如，统计电影的平均评分并按评分降序排列。
  - 这种操作使得 MongoDB 能够高效处理复杂查询。

###  MongoDB 的应用场景

- **大数据存储**：
  - 适合存储海量非结构化数据。
  - 例如，日志系统、搜索引擎。
  - 这种场景下，MongoDB 的高扩展性和高性能表现优异。
- **高并发读写**：
  - 适合高并发场景，如实时分析系统。
  - 例如，电商网站的订单系统。
  - 这种场景下，MongoDB 的高可用性和弱化锁机制表现优异。
- **动态 Schema**：
  - 适合数据结构频繁变化的场景。
  - 例如，社交媒体的用户数据。
  - 这种场景下，MongoDB 的动态 Schema 表现优异。

### MongoDB 与其他 NoSQL 数据库的比较

- **MongoDB vs Redis**：
  - Redis 是内存数据库，适合缓存和实时数据处理。
  - MongoDB 是文档数据库，适合存储和查询复杂数据。
  - 例如，Redis 适合存储会话数据，MongoDB 适合存储用户数据。
- **MongoDB vs HBase**：
  - HBase 是列式数据库，适合大规模分布式存储。
  - MongoDB 更适合灵活的文档存储。
  - 例如，HBase 适合存储日志数据，MongoDB 适合存储商品数据。

### MongoDB 的安装与使用

- **安装**：
  - 可以通过包管理工具（如 apt、yum）或官方安装包安装。
  - 例如，使用 `apt-get install mongodb` 安装。
  - 这种安装方式使得 MongoDB 能够快速部署。
- **客户端工具**：
  - 可以使用 MongoDB Compass（图形化工具）或 mongo shell（命令行工具）进行操作。
  - 例如，使用 `mongo` 命令进入命令行工具。
  - 这种工具使得 MongoDB 的操作更加便捷。
- **基本命令**：
  - 切换数据库：`use <database_name>`
  - 插入文档：`db.collection.insertOne({...})`
  - 查询文档：`db.collection.find({...})`
  - 更新文档：`db.collection.updateOne({...}, {$set: {...}})`
  - 删除文档：`db.collection.deleteOne({...})`
  - 这些命令使得 MongoDB 的操作更加直观。

### MongoDB 的聚合操作

- **聚合管道**：

  - 通过多个阶段（Stage）对数据进行处理，如 `$match`（过滤）、`$group`（分组）、`$sort`（排序）等。

  - 例如，统计电影的平均评分并按评分降序排列：

    ```javascript
    db.movies.aggregate([
      { $unwind: "$genres" },
      { $group: { _id: "$genres", avgRating: { $avg: "$rating" } } },
      { $sort: { avgRating: -1 } }
    ]);
    ```

  - 这种操作使得 MongoDB 能够高效处理复杂查询。

### MongoDB 的适用场景与局限性

- **适用场景**：
  - 非结构化数据存储。
  - 高并发读写场景。
  - 数据结构频繁变化的场景。
- **局限性**：
  - 不支持复杂的事务处理（如多文档事务）。
  - 不适合强一致性要求的场景。

### MongoDB Compass 的使用

- **打开 MongoDB Compass**：
  - MongoDB Compass 是 MongoDB 官方提供的图形化管理工具，支持直观的数据操作。
  - 在 Compass 中，可以直接输入查询语句（如 `{ "title": "Inception" }`），按回车后，符合条件的电影数据会显示在界面中。
  - 这种方式与在 MongoDB Shell 中执行查询的效果一致，但 Compass 提供了更友好的可视化界面。
  - Compass 还支持数据导入、导出、索引管理、性能分析等功能。
- **数据集来源**：
  - 数据集来自 GitHub 上的一个开源项目，文件名为 `movies.json`，大小约为几百兆。
  - 该文件包含大量电影信息，如电影标题、类型、评分、演员等。
  - 通过 MongoDB Compass 的 `Import Data` 功能，可以将 `movies.json` 文件导入到 MongoDB 的某个集合中。
  - 导入时，Compass 会自动解析 JSON 文件的结构，并生成对应的集合和文档。
  - 导入完成后，可以在 Compass 中查看集合的结构和数据。

聚合操作（Aggregation）

- **聚合管道（Aggregation Pipeline）**：

  - 聚合管道是 MongoDB 中用于处理数据的强大工具，由多个阶段（Stage）组成，每个阶段对数据进行处理。

  - 例如，`$project` 阶段类似于 SQL 中的 `SELECT`，用于选择特定字段。

  - 在 `$project` 阶段，可以通过设置字段值为 `1` 或 `0` 来选择或排除字段。例如：

    ```json
    { "$project": { "title": 1, "rating": 1, "_id": 0 } }
    ```

    表示只选择 `title` 和 `rating` 字段，并排除 `_id` 字段。

- **展开数组（$unwind）**：

  - 使用 `$unwind` 阶段展开数组字段。例如，电影的类型（genres）是一个数组，展开后每条记录对应一个类型。

  - 示例：

    ```json
    { "$unwind": "$genres" }
    ```

    展开后，如果一部电影有多个类型（如动作、科幻），则会生成多条记录，每条记录对应一个类型。

- **分组与平均值（$group 和 $avg）**：

  - 使用 `$group` 阶段按类型分组，并计算每个类型的平均评分。

  - 示例：

    ```json
    { "$group": { "_id": "$genres", "avgRating": { "$avg": "$rating" } } }
    ```

    表示按 `genres` 字段分组，并计算每个类型的平均评分。

- **排序（$sort）**：

  - 使用 `$sort` 阶段按平均评分降序排列结果。

  - 示例：

    ```json
    { "$sort": { "avgRating": -1 } }
    ```

    表示按 `avgRating` 字段降序排列，评分最高的类型排在最前面。

- **保存聚合管道**：

  - 可以将聚合管道保存为模板，方便后续重复使用。
  - 例如，保存为 `sample` 模板后，可以直接运行该模板获取结果，无需重新编写聚合管道。

### MongoDB 与 Spring Data 集成

- **简单示例**：

  - 定义一个 `Person` 类，使用 `@Document` 注解映射到 MongoDB 的集合。

  - 示例代码：

    ```java
    @Document(collection = "people")
    public class Person {
        @Id
        private String id;
        private String firstName;
        private String lastName;
        // Getters and Setters
    }
    ```

  - 通过 `MongoRepository` 实现增删改查操作。

  - 示例代码：

    ```java
    public interface PersonRepository extends MongoRepository<Person, String> {
        List<Person> findByFirstName(String firstName);
        List<Person> findByLastName(String lastName);
    }
    ```

  - 插入曹操、刘备、孙权三个人的数据，并通过 `findByFirstName` 和 `findByLastName` 查询。

- **复杂示例**：

  - 数据存储在 MySQL 和 MongoDB 两个数据库中。

  - MySQL 存储人物基本信息（如姓名、年龄），MongoDB 存储人物图片（Base64 编码）。

  - 通过 Spring Data 将两个数据源的数据合并返回。

  - 示例代码：

    ```java
    public PersonDTO getPersonInfo(String id) {
        PersonInfo info = mysqlRepository.findById(id); // 从 MySQL 获取基本信息
        String image = mongoRepository.findImageById(id); // 从 MongoDB 获取图片
        return new PersonDTO(info, image); // 合并返回
    }
    ```

  - 例如，查询曹操的信息时，从 MySQL 获取姓名和年龄，从 MongoDB 获取图片。

### MongoDB 的索引

- **单列索引**：

  - 在单个字段上创建索引，支持升序或降序。

  - 示例：

    ```json
    db.collection.createIndex({ "age": 1 })
    ```

    表示在 `age` 字段上创建升序索引。

- **复合索引**：

  - 在多个字段上创建索引，支持多级排序。

  - 示例：

    ```json
    db.collection.createIndex({ "firstName": 1, "lastName": 1 })
    ```

    表示在 `firstName` 和 `lastName` 字段上创建复合索引。

- **地理空间索引**：

  - 支持二维地理空间索引，用于查找附近的点。

  - 示例：

    ```json
    db.collection.createIndex({ "location": "2dsphere" })
    ```

    表示在 `location` 字段上创建地理空间索引。

  - 地理空间索引要求字段为包含两个数值的数组（如经度和纬度）。

### 地理空间查询

- **查找附近的点**：

  - 使用 `$near` 操作符查找距离某个点最近的记录。

  - 示例：

    ```json
    db.collection.find({
        "location": {
            "$near": {
                "$geometry": { "type": "Point", "coordinates": [100, 90] },
                "$maxDistance": 10
            }
        }
    })
    ```

    表示查找距离 `[100, 90]` 最近的记录，最大距离为 10。

- **自定义查询**：

  - 通过 `MongoRepository` 自定义查询方法。

  - 示例代码：

    ```java
    public interface LocationRepository extends MongoRepository<Location, String> {
        List<Location> findByPropertiesNear(Point point, Distance distance);
    }
    ```

    表示定义 `findByPropertiesNear` 方法，查找距离某个点最近的记录。

### MongoDB 的优势

- **灵活的数据模型**：
  - 不同文档可以有不同的字段，无需预先定义 Schema。
  - 例如，存储手机信息时，不同手机可以有不同的参数（如质量、价格）。
- **无需表连接**：
  - 在关系型数据库中，需要通过表连接查询关联数据。
  - 在 MongoDB 中，所有数据可以存储在一个集合中，无需连接操作。
- **高效查询**：
  - 支持复杂查询和索引，查询性能高。
  - 例如，查找待机时间大于 100 且屏幕为 OLED 的手机。

### 分片（Sharding）

- **分片概述**：
  - 将数据分布到多台服务器上，支持水平扩展。
  - 例如，按 ID 范围将数据分布到不同的分片服务器上。
- **分片策略**：
  - 分片策略需要确保数据均匀分布，避免热点问题。
  - 例如，使用哈希分片策略将数据均匀分布到多个分片上。





---

# 16-Neo4j & Graph Computing

##  MongoDB 地理空间查询中的 `maxDistance` 问题

- **问题描述**：

  - 在地理空间查询中，`maxDistance` 的值会影响查询结果的数量。
  - 例如，设置 `maxDistance` 为 `0.1` 时，只能找到一个结果；设置为 `0.2` 时，能找到两个结果；设置为 `1` 时，能找到三个结果。

- **原因分析**：

  - `maxDistance` 的单位取决于前面的设置。如果没有明确设置单位，`1` 可能代表的是“度”（经纬度的单位），而不是具体的距离单位（如米或公里）。
  - 因此，`1` 已经是一个很大的值，导致查询范围过大，返回的结果较多。

- **解决方案**：

  - 在代码中明确指定 `maxDistance` 的单位，例如设置为 `100 公里`，避免歧义。

  - 示例代码：

    ```java
    Point point = new Point(100, 90);
    Distance distance = new Distance(100, Metrics.KILOMETERS);
    List<Location> locations = locationRepository.findByLocationNear(point, distance);
    ```

  - 这样，查询的范围和单位都清晰明确，避免了因单位不明确导致的查询结果不一致问题。

## MongoDB 分片（Sharding）机制

- **分片概述**：
  - 分片是 MongoDB 用于水平扩展数据存储的机制，将数据分布到多台服务器上。
  - 分片的核心思想是将一个集合（Collection）切分成多个小块（Chunk），并将这些块分布到不同的分片服务器（Shard Server）上。
- **分片与 MySQL 分区的区别**：
  - **MySQL 分区**：
    - 分区是在表级别进行的，用户可以手动选择分区策略（如哈希分区、范围分区等）。
    - 分区后，数据存储在同一台服务器上，分区信息由 MySQL 管理。
  - **MongoDB 分片**：
    - 分片是自动进行的，MongoDB 会根据数据量和负载自动将数据切分并分布到不同的分片服务器上。
    - 分片对用户透明，用户无需关心数据具体存储在哪个分片上。
- **分片的工作原理**：
  - **Router**：
    - MongoDB 引入了一个 Router 角色，负责记录每个集合的分片信息（如哪些 Chunk 存储在哪些 Shard Server 上）。
    - 客户端通过 Driver 与 Router 交互，Router 根据分片信息将查询请求转发到相应的 Shard Server。
  - **Chunk**：
    - 每个 Chunk 是一个数据块，大小通常为 128MB。
    - 当 Chunk 的大小超过阈值时，MongoDB 会自动将其分裂成更小的 Chunk。
  - **数据均衡**：
    - MongoDB 会自动平衡各个 Shard Server 上的 Chunk 数量，确保数据分布均匀。
    - 例如，当新增一个 Shard Server 时，MongoDB 会将部分 Chunk 迁移到新服务器上，以保持各服务器的负载均衡。
- **分片的适用场景**：
  - 数据量过大，单台服务器无法存储。
  - 高并发读写场景，需要提高写入性能。
  - 内存或硬盘资源不足，需要扩展存储容量。

## 图数据库（Neo4j）

- **图数据库的优势**：
  - 高效处理复杂关系查询，适合社交网络、推荐系统、知识图谱等场景。
  - 灵活的数据模型，支持动态添加节点和边。
- **Neo4j 的核心特性**：
  - Cypher 查询语言，支持灵活的关系遍历和优化。
  - 高效的内部存储机制，通过链表结构快速遍历节点和边。
  - 支持集群模式，适合大规模图数据的存储和处理。

### 图数据库与关系型数据库的对比

- **关系型数据库的局限性**：
  - **JOIN 操作性能差**：
    - 在关系型数据库中，查询复杂关系需要多次 JOIN 操作，性能随数据量增加而下降。
    - 例如，查询“谁买过草莓冰淇淋”需要多次 JOIN，效率较低。
  - **数据结构僵化**：
    - 关系型数据库需要预先定义表结构，不适合数据结构频繁变化的场景。
- **图数据库的优势**：
  - **高效的关系查询**：
    - 图数据库通过遍历边来查询关系，无需 JOIN 操作，性能更高。
  - **灵活的数据模型**：
    - 图数据库支持动态添加节点和边，适合复杂和变化的数据结构。

### Neo4j 查询语言：Cypher

- **Cypher 简介**：

  - Cypher 是 Neo4j 的查询语言，用于描述和查询图数据。
  - Cypher 的语法类似于 SQL，但更专注于图数据的遍历和关系查询。

- **Cypher 示例**：

  - 查询用户的好友：

    ```cypher
    MATCH (u:User {name: "Alice"})-[:FRIEND]->(f:User)
    RETURN f.name
    ```

  - 查询用户的好友的好友：

    ```cypher
    MATCH (u:User {name: "Alice"})-[:FRIEND]->(f:User)-[:FRIEND]->(ff:User)
    RETURN ff.name
    ```

###  Neo4j 的内部存储机制

- **节点和边的存储**：
  - 节点和边分别存储，每个节点和边都有一个唯一的 ID。
  - 节点存储其第一个属性和第一条边的 ID，其他属性和边通过链表连接。
  - 边存储其起点、终点、前一条边和下一条边的 ID。
- **高效的关系遍历**：
  - 通过链表结构，Neo4j 可以快速遍历节点的所有边，无需扫描全表。
  - 示例：查询朋友的朋友：
    - 从节点 A 的第一条边开始，沿着链表遍历所有边，找到朋友的朋友。

### Neo4j 的集群和扩展

- **集群模式**：
  - Neo4j 支持集群模式，将图数据分布到多台服务器上。
  - 每个子图可以存储在不同的服务器上，子图之间有一定的重叠，避免数据丢失。
- **读写分离**：
  - 写操作只能在主节点上执行，读操作可以在所有节点上执行。
  - 主节点和从节点之间通过同步机制保持数据一致性。

### Neo4j 的实践应用

- **嵌入式模式**：
  - Neo4j 可以嵌入到应用程序中，与 Spring Boot 等框架集成。
  - 示例：在 Spring Boot 中嵌入 Neo4j，实现图数据的存储和查询。
- **大规模数据处理**：
  - 对于大规模图数据（如银行转账记录），可以将图数据切分成多个子图，存储在不同的服务器上。
  - 使用 Spark 等工具对图数据进行处理和分析。

## 图数据库的核心

- **节点（Node）**：
  - 表示实体，如用户、商品、电影等。
  - 节点可以带有属性（如用户的姓名、年龄等）。
  - 示例：用户节点 `(u:User {name: "Alice", age: 30})`。
- **边（Edge）**：
  - 表示节点之间的关系，如“关注”、“购买”、“出演”等。
  - 边可以带有属性（如关系的创建时间、权重等）。
  - 示例：用户关注关系 `(u1:User)-[:FOLLOWS {since: "2023-01-01"}]->(u2:User)`。
- **图数据库的优势**：
  - **高效处理复杂关系**：
    - 在关系型数据库中，查询复杂关系（如“朋友的朋友”）需要多次 JOIN 操作，性能较差。
    - 在图数据库中，查询复杂关系只需沿着边遍历，无需全表扫描，性能更高。
  - **灵活的数据模型**：
    - 图数据库支持动态添加节点和边，适合数据结构频繁变化的场景。

###  图数据库的查询语言：Cypher

- **Cypher 简介**：

  - Cypher 是 Neo4j 的查询语言，用于描述和查询图数据。
  - Cypher 的语法类似于 SQL，但更专注于图数据的遍历和关系查询。

- **Cypher 示例**：

  - 查询用户的好友：

    ```cypher
    MATCH (u:User {name: "Alice"})-[:FRIEND]->(f:User)
    RETURN f.name
    ```

  - 查询用户的好友的好友：

    ```cypher
    MATCH (u:User {name: "Alice"})-[:FRIEND]->(f:User)-[:FRIEND]->(ff:User)
    RETURN ff.name
    ```

  - 查询用户的朋友的朋友，并去重：

    ```cypher
    MATCH (u:User {name: "Alice"})-[:FRIEND*1..2]->(f:User)
    RETURN DISTINCT f.name
    ```

### 图数据库的应用场景

- **社交网络**：

  - 查询用户的好友、好友的好友等关系。

- **推荐系统**：

  - 基于用户的行为和关系，推荐相关商品或内容。

  - 示例：协同过滤算法，推荐用户喜欢的朋友也喜欢的书。

    ```cypher
    MATCH (u:User {name: "Alice"})-[:LIKES]->(b:Book)<-[:LIKES]-(f:User)-[:LIKES]->(rec:Book)
    RETURN DISTINCT rec.title
    ```

- **知识图谱**：

  - 构建和查询复杂的实体关系网络。

- **金融风控**：

  - 检测异常交易模式，如洗钱、非法集资等。

### 图数据库的性能优势

- **复杂关系查询的高效性**：

  - 在关系型数据库中，查询复杂关系需要多次 JOIN 操作，性能随数据量增加而下降。

  - 在图数据库中，查询复杂关系只需沿着边遍历，性能更高。

  - 示例：查询用户使用的负载均衡器（Load Balancer）：

    ```cypher
    MATCH (u:User)-[*1..5]->(a:Asset)
    WHERE a.status = "down"
    RETURN DISTINCT a
    ```

    - 该查询只需一条 Cypher 语句，而在关系型数据库中需要多次 JOIN 操作。

- **灵活的数据模型**：

  - 图数据库支持动态添加节点和边，适合数据结构频繁变化的场景。

### 图神经网络与图数据库的结合

- **图神经网络（GNN）**：
  - 用于对图数据进行分类和预测，如社交网络中的用户分类、金融交易中的异常检测。
  - 图注意力网络（GAT）是一种常用的 GNN 模型，通过注意力机制聚合节点和边的特征。
- **应用场景**：
  - 社交网络分析：识别社交网络中的关键用户。
  - 金融风控：检测异常交易模式。





------

# 17 -Log-Structured DB& Vector DB

## 课前Redis讲评

课前讲了作业中`Redis的超时`设置（比如3600秒），有几个要考虑的问题：

1. **缓存雪崩**：一开始我把数据库中10万本书的信息都缓存在Redis中，那最初大量的访问都是走Redis的。但当3600秒到了之后，Redis中的对象会**全部失效**，这意味着之后大量的访问书的请求在Redis中是无法命中的，于是要到数据库硬盘上重新去load

   官方定义：Redis中缓存的数据大面积同时失效，或者Redis宕机，从而会导致大量请求直接到数据库，压垮数据库。

   解决：10万本分成10个1000本，然后每小时失效1000个（即不要让所有缓存同时过期，也可以通过设置缓存的过期时间为随机值来避免）

2. **缓存击穿：**比如碰上双11，突然会有10万个请求**同时进来**都要找同一本书，而这一本书恰好在Redis中没有，这意味着数据库要同时去处理大量的请求，但其实处理的都是一个数据。此时缓存就好像没有一样，就给击穿了，尽管最后这条数据会被load到缓存里

   官方定义：缓存击穿是指某个热点数据在缓存中失效的瞬间，大量的并发请求同时访问该数据，由于该数据在缓存中失效，大量请求同时打到数据库，造成数据库压力骤增。这种情况通常发生在热点数据或访问频繁的数据上。

   解决：**加锁**。当缓存失效时，通过加锁的方式保证只有一个线程去查询数据库并更新缓存，其他线程等待缓存更新完成后再获取数据，此时就是走Redis了，读数据库就只有一次。

3. **缓存穿透：**客户端频繁访问一些根本不存在的缓存数据，由于缓存中没有这些数据的记录，每次请求都直接打到数据库，导致数据库压力增大。这通常是由于用户输入非法或恶意构造的请求引发的。

   解决：在前面要做个过滤，比如布隆过滤器（不存在的数据一定会返回不存在，所以如果布隆过滤器判定该key不存在，则直接返回，不必查询缓存或数据库。但是它说有不一定真有。）

   第一个问题和过期时间有关，后两个问题和数据库与缓存之间的数据同步有关。所以在设计Redis时有很多问题要考虑。

![92af2dee3ac970b7d545b4156f4c41c2.jpg](C:/Users/77043/Desktop/应用/17-18/92af2dee3ac970b7d545b4156f4c41c2.jpg)

讲向量数据库Vector Database是因为现在很多AI的项目在用Vector DB做处理，比如ChatGPT。

## Log-Structured Database 日志结构数据库

它的存在是为了解决一个**热点数据问题**。

传统数据库（如MySQL、MongoDB、Neo4j等）存在一个`前提条件`：所有数据被访问的概率相似，且数据在语义上没有明显差异。

考虑购物节的场景，期间会有很多新插入的订单，而这些新数据被访问的频率极高（如用户查看订单状态、处理情况、运送信息等）。传统数据库将所有订单数据存储在同一张表中，无法区分新订单与老订单，这会导致：数据访问效率低下，尤其当订单量达到百万级别时，每次查找都需在大量数据中检索，即使使用B+树等索引结构，速度仍然较慢。即使采用分区Partition等方法，仍有不足：

如果按插入时间进行分区，则需要在表中包含时间戳（timestamp），以支持按时间查询，这样就无法同时按用户名或地域等其他维度进行分区。此外，**子分区SubPartiton**也比较复杂：例如，先按用户名进行哈希分区，再在每个用户名分区内按时间戳分区。查找时需先确定所在的分区，再在分区内进行查找，操作复杂且不便。

所以总的来说，他们对**热点数据的支撑**会弱一点。

此时我们就用到了日志数据库。

## LSM-Tree:Log-Structured Merge Tree 日志结构合并树

- 是一种分层、有序、面向磁盘的数据结构，其核心思想是充分利用磁盘批量顺序写性能远高于随机写性能的特点

（1）什么是日志结构？前面数据库讲undo，redo和bin log的时候提到了，是**顺序写**的，即以append的模式追加写入，不存在删除和修改（修改也是通过插入新数据）。

- 这种结构虽然大大提升了数据的写入能力，却是以牺牲部分读取性能为代价，故此这种结构通常适合于写多读少的场景

（2）为什么叫合并树？即把`热数据`放在树里面比较`高`的地方，这样从根往下遍历的时候能比较快的读到新数据。旧数据通过不断的合并沉到树的下面。（数据被分了层，数据热度和level相关）

![0690943f213e75324e2f57428ce19813.jpg](C:/Users/77043/Desktop/应用/17-18/0690943f213e75324e2f57428ce19813.jpg)

**双内存表机制**确保在一个内存表写满时，它的角色会切换成`Immutable Memtable`（即冻结），然后另一个内存表可以立即接收新的写入（写操作不能停止，系统需要持续接受新的数据写入）。此外，满的内存表需要被持久化到硬盘，以释放内存空间供新的写入使用。这个过程需要一定的时间，不可避免会有写入延迟。将满的内存表**冻结**，即转换为不可修改状态，能确保数据的一致性和完整性。

![c0f334185f0d1625302d7ac12b2949ff.jpg](C:/Users/77043/Desktop/应用/17-18/c0f334185f0d1625302d7ac12b2949ff.jpg)

## SSTable(Sorted String Table)

**SSTable的特点**

- 存储的是<键,值>格式的字节数据 
- 字节数据的长度随意，没有限制 
- 数据顺序写入
- 键可以重复，键值对不需要对齐（所以需要一个索引记录key和offset）
- 随机读取操作非常高效

![df21f007178160d0df42c15fdd6ebe2c.jpg](C:/Users/77043/Desktop/应用/17-18/df21f007178160d0df42c15fdd6ebe2c.jpg)


**SSTable的限制**

- 一旦SSTable写入硬盘后，就是不可变的，因为插入或者删除需要对SSTable文件进行大量的I/O操作 
- 不适合随机读取和写入，因为效率很低，原因同上一条

### 写放大问题

- 写入的时候可能有个阻塞问题，为啥？因为它写入的时候有可能需要去做合并Compaction，比如L0层满了之后，它要往L1层去落，那么刚才讲了一个极端情况是L1层你落下来之后也满了，又要往L2层落，以此类推，每一层可能都会满。不断地往下compact导致**实际写入的数据量远大于真正的数据量**。

### 读放大问题

- 那读呢？是存在这么一个问题，就是我在找一个数据的时候，我先到内存表里；找不到，我再到这个 L0层找，找不到我也不能说这数据不存在，有可能它太老，它落到底下去了，于是我一层层找，极有可能就是最后你在很找了很多层你才找到。而且你在不同的层里面可能还存着不同的版本。因为我们刚才说了，它的改写是通过append追加得到的，那也就是说你如果有老版本的话，它会在更低的层里面，如果没有经过compaction，这个数据还是在的，只有compact才有一次机会可能把它给删掉。这个过程可能需要不止一次I/O。特别是range query的情况，影响很明显。**限制了AP查询的性能**。
- 优化：同样可以用一个布隆过滤器

### RocksDB

![796fb96acb052ba7c55f93a1c6a6cb02.jpg](C:/Users/77043/Desktop/应用/17-18/796fb96acb052ba7c55f93a1c6a6cb02.jpg)

和Neo4j类似，有两种运行方式：一种是他在后台作为一种服务，另一是它嵌入到应用中

![img](C:/Users/77043/Desktop/应用/17-18/996d370a5681de86082d76cd4fd14789.jpg)

**注意的点：**

- 在写之前，同样要先写Write Ahead Log
- 有多个Immutable Memtable，因为写操作数量比较多
- L0层是允许key的范围有重叠，从L1之后往下不允许范围有重叠
- Compaction过程中可以去掉旧数据
- Manifest Log不断追踪文件系统的变化，相当于记录SSTable的变化

课上运行了一个**嵌入式**的RocksDB的Java程序，要注意的是在实现增、删、查方法时需要添加**synchronized**关键词，防止多个用户访问时出错，比如一个正在删，一个正在查

### HTAP(Hybrid Transactional/Analytical Processing)

- 数据存储方式的选择（按行存储 vs 按列存储）直接影响数据库对不同类型工作负载的支持。

##### 行存储与列存储的区别

- 行存储:数据以“行”为单位存储，每一行包含一个完整的记录。

  适用于:在线事务处理（OLTP）

  - 低延迟、高并发的随机读写操作。
  - 典型场景：订单处理、用户登录等。

  - 优点:
    - 快速插入和更新单条记录。
    - 适合频繁的随机访问。
  - 缺点:
    - 大规模的顺序读取（如统计分析）效率低下。

- 列存储：数据以“列”为单位存储，每一列的数据集中存放。

  适用于:在线分析处理（OLAP）

  - 高效的大规模数据读取和聚合操作。
  - 典型场景：销售统计、报表生成等。

  - 优点：
    - 高效的列级压缩和大规模数据读取。
    - 适合大规模顺序访问和分析。
  - 缺点：
    - 插入和更新单条记录较慢，尤其是高并发场景。

### OLTP与OLAP对存储格式的不同需求

- 在线事务处理（OLTP）
  - 特点：
    - 高并发、低延迟的随机读写。
    - 处理大量短小的事务（如订单、用户信息）。
  - 需求：
    - 快速的单条记录插入和更新。
    - 高效的随机访问支持。
- 在线分析处理（OLAP）
  - 特点：
    - 低并发、高吞吐量的大规模数据分析。
    - 处理复杂的查询和聚合操作。
  - 需求：
    - 高效的顺序读取和列级聚合。
    - 优化的列存储以提升查询性能。

![img](C:/Users/77043/Desktop/应用/17-18/bba06d63285b8c92c7fb5807fbec5573.jpg)

##### 混合存储的挑战

- 不同需求的冲突：OLTP和OLAP对存储格式的需求相互矛盾，单一的存储格式难以兼顾两者的性能。
- 系统复杂性：在一个系统中同时支持行存和列存需要复杂的存储管理和数据一致性维护。

##### 解决方案

1. **双存储方案（Dual Storage）**：
   - 同时维护行存和列存两份数据。
   - 优点：
     - 完全优化 OLTP 和 OLAP 各自的性能。
   - 缺点：
     - 存储空间浪费严重（数据存储空间翻倍）。
     - 保持两份数据的**一致性**极为复杂，易出现数据不一致问题。
2. **根据数据的访问情况进行行存和列存的自动转换**

RocksDB没法直接实现行存到列存的转换，但他走了一个`折中路线`

##### RocksDB 的处理方式

- 列族（Column Family）
  - 很多NoSQL数据库都想到这种方法，很像MySQL的`垂直分区`（但是MySQL自身不支持，因为维护起来太麻烦，找第三方工具能实现），而在NoSQL中垂直分区是很常见的
  - 将数据分成不同的列族，每个列族独立管理和优化。
  - 例如，订单表中将与 `sale` 相关的列存储在一个列族中，以优化OLAP查询。
  - 其他订单相关信息继续使用行存列族，优化OLTP操作。
- 预写日志（WAL）
  - 所有列族共享一个预写日志和Manifest Files，确保数据一致性和可靠性。
- 优化折中
  - 通过垂直分区和列族机制，实现部分行存和列存的优化，兼顾OLTP和OLAP的需求。

### 2.7 RocksDB的读写流程

##### 2.7.1 写流程

![img](C:/Users/77043/Desktop/应用/17-18/ec2835d7937f15698cb50da86e29dbcc-1736860466178-36.jpg)

**解决：**

![image-20250114212050520](C:/Users/77043/Desktop/应用/17-18/image-20250114212050520.png)

增加一个**收集分发层**，比如**Apache Flink**（一种流处理框架，广泛应用于字节跳动、阿里巴巴等大型平台，用于高效处理和分配数据）

###### 数据处理流程

1. 数据接入：数据首先接入Flink进行实时处理和分发。
2. 数据暂存与分配：
   - 确保大量数据能够被快速接收和暂存（写阻塞是缓存数据）
   - 将数据根据策略分配到不同的Collector进行后续处理。
3. 数据写入存储系统：Collector负责将数据从内存写入硬盘，确保数据的持久化存储。

![1736861088183](C:/Users/77043/Desktop/应用/17-18/1736861088183.png)

###### Collector管理与监控

- 多Collector并行写入：系统中存在多个Collector，能够并行处理写入请求，提升写入效率。
- 监控Collector状态：
  - 关键监控指标：
    - **内存大小**：每个Collector的总内存容量。
    - **剩余内存**：当前Collector的可用内存量。
    - **写入进度**：数据写入到内存和从内存落盘的进度。
  - 监控目的：实时了解各Collector的负载情况，确保数据分配的合理性。

###### 数据分配策略

- 动态分配策略
  - 根据内存使用情况分配：优先将新数据分配给空闲内存最多的Collector，以优化资源利用。
  - 负载均衡：确保各Collector之间的负载均衡，避免某些Collector过载而导致写阻塞。
- 具体步骤：
  1. 检测Collector状态：实时监控各Collector的内存使用情况和写入进度。
  2. 选择合适的Collector：根据空闲内存量，选择最合适的Collector接收新的Producer数据。
  3. 分配数据：将数据发送到选定的Collector，确保写入操作的高效和连续性。

###### 优势

- 避免写阻塞：通过合理的数据分配，减少单个Collector的压力，避免写操作被阻塞。
- 提升系统可用性：保证写入操作的连续性和高效性，提高事务处理的可用性和系统响应速度。
- 增强系统扩展性：过增加Collector数量，可以线性扩展系统的写入能力，适应更高的并发写入需求。

##### 2.7.2 读流程

![img](C:/Users/77043/Desktop/应用/17-18/76a51c10f6e4a1181c8c6b2123f8f183.jpg)

**解决：**

![image-20250114213236709](C:/Users/77043/Desktop/应用/17-18/image-20250114213236709.png)

###### 列存储在RocksDB中采用分块存储策略：

- 数据量较大时（如100万条记录），不能先全部存这100万跳记录的某一列，然后在存下一列。
- 分块存储策略：
  - 将数据按列分成多个数据块，每个数据块包含前m行的某一列数据。
  - 每个大块内先存储第一列的数据，接着存储第二列，依此类推。
  - 数据块按行切分，确保在每个大块内按列存储，提升查询效率。

![image-20250114214247380](C:/Users/77043/Desktop/应用/17-18/image-20250114214247380.png)

###### 支持混合存储策略：

- 支持同时使用行存和列存，满足OLTP和OLAP的不同需求。

![image-20250114214610756](C:/Users/77043/Desktop/应用/17-18/image-20250114214610756.png)

几乎所有数据库都支持HTAP功能（包括MySQL），用户可以选择打不打开，但是打开之后会影响性能

#### 2.8 HTAP系统整合

![image-20250114214845186](C:/Users/77043/Desktop/应用/17-18/image-20250114214845186.png)

根据发送过来的请求来决定是在行存还是列存上去做操作。行存和列存是在**互相转换**的，不需要在任何时刻两个同时存在，数据在行存和列存上做转换，只保留一份。

![image-20250114215047950](C:/Users/77043/Desktop/应用/17-18/image-20250114215047950.png)

我们只是以RocksDB为例来讲了为什么数据库中需要行存和列存来支持HTAP，事实上，关系型数据库、文档数据库等也都是同时支持AP和TP的。

## Vector Database向量数据库

![image-20250115010155051](C:/Users/77043/Desktop/应用/17-18/image-20250115010155051.png)

#### 3.1 定义：

专门用于存储和查询高维向量（嵌入）的数据库，主要用于支持人工智能模型中的相似性搜索。

#### 3.2 向量数据库解决的问题：

###### AI模型中的嵌入需求

- 嵌入（Embedding）

  - 将目标对象（如文本、图像、视频）数值化，转化为高维向量。
  - 生成的向量包含对象的特征或属性信息。

- 应用场景：

  - **图像分类**：将图像像素（如224x224像素*3通道）摊平成一维向量作为嵌入。

  - **自然语言处理**：将单词通过词向量模型（如Word2Vec）转换为向量表示。

    - 使用One-Hot编码：每个单词表示为一个稀疏高维向量，维度等于词汇表大小（如3万个单词）。单词a在第一个位置上为1其他位置都是0，单词b在第二个位置上为1其他位置都是0（需要3万个位来表示）

    - 缺点：
      - 维度过高，存储空间大。
      - 向量之间正交，无法表示单词间的**相似性**。

  - **降维嵌入**：

    - 将单词嵌入压缩到较低维度（如上图中的5维，每一位代表一种“属性”）。
    - 优点：
      - 降低存储空间需求。
      - 向量之间可以计算相似性，反映单词间的关系。

![image-20250115011311090](C:/Users/77043/Desktop/应用/17-18/image-20250115011311090.png)

#### 3.3 向量数据库的工作原理：

###### 存储向量

- 存储内容：向量数据库存储各种对象的嵌入向量。
- 相似性搜索：根据查询向量，查找数据库中与之最相近的向量，支持相似对象的检索。

###### 向量与传统数据库的区别

- 传统数据库：主要支持精确匹配查询。
- 向量数据库：支持基于向量相似度的模糊匹配查询。

###### 常见相似度度量

- 余弦相似度（Cosine Similarity）：
  - 计算两个向量的夹角余弦值，范围[-1, 1]。
  - 越接近1，表示向量方向越相近。
- 欧几里得距离（Euclidean Distance）：计算两个向量之间的直线距离(用两点之间距离公式)。
- 曼哈顿距离（Manhattan Distance）：计算两个向量在各维度上的绝对差值之和。
- 其他相似度度量：Jaccard相似度、Hamming距离等，根据具体应用选择。

#### 3.4 向量数据库的索引方法

###### 维度处理

- 高维向量的挑战：存储空间大，查询效率低（之前的例子，一张图片变成向量会有224 * 224 * 3位）

- 降维方法：

  - 随机投影：
    - 使用随机矩阵将高维向量投影到低维空间。（1 * n的向量乘n * m的矩阵变成1 * m）
    - 当然也可以从低维变成高维，所以本质上是**维度的压缩或扩张**

  ![image-20250115012232847](C:/Users/77043/Desktop/应用/17-18/image-20250115012232847.png)

  - 量化（Product Quantization）：
    - 将高维向量拆分成小块，映射到预定义的代码本（Codebook）中，减少存储空间。
    - 本质上是做了一个**聚类**操作
    - 如下图所示，如果A和B经过分割然后量化后都有3个code，可通过比较匹配上的有多少个，匹配的越多表明越相似

  ![image-20250115012419901](C:/Users/77043/Desktop/应用/17-18/image-20250115012419901.png)

###### 其他计算近似的算法

- 位置敏感敏感哈希（Locality-sensitive hashing）
  - 相似的向量会进入同一个哈希桶且位置靠近（如下图所示）

![image-20250115013255355](C:/Users/77043/Desktop/应用/17-18/image-20250115013255355.png)

- 图结构方法
  - 层次化可导航小世界（HNSW）：构建多层次的图结构，每个节点（代表一个“群”，群内的向量相似度都比较高）连接相似的节点，支持高效的近邻搜索。

![image-20250115013737504](C:/Users/77043/Desktop/应用/17-18/image-20250115013737504.png)

###### 通过过滤来优化

一个向量包含着元数据（比如图片信息，视频信息和音频信息）

在进行相似度查找时，有两种过滤方式：

- Pre-filtering：先把不相关的过滤掉（比如我只想找相似的图片，那我就先过滤掉视频和音频），再根据相似度排序
- Post-filtering：比如是多模态的搜索，然后对结果进行过滤，如果不满意过滤后的结果还可以退回到初始的结果进行进一步处理

![image-20250115013949182](C:/Users/77043/Desktop/应用/17-18/image-20250115013949182.png)

#### 3.5 以Pinecone这个向量数据库为例

![image-20250115014728902](C:/Users/77043/Desktop/应用/17-18/image-20250115014728902.png)

可以发现，它也有**主从备份**，然后它存的是**索引Index**，可以理解成传统关系数据库的表(Table)。每个Index在Pinecone中都是一个独立的数据结构,用于存储和检索高维向量。创建索引时，需要定义`向量维度`和`相似度的度量方式（比如余弦相似度）`。此外，索引中有**sharding分片**

![image-20250115015251316](C:/Users/77043/Desktop/应用/17-18/image-20250115015251316.png)

- 在创建完索引后，可以将嵌入向量插入到索引中（相当于往表中插入一条数据），也可以进行删除操作。

- 查找时，输入查询向量，可以获取Top K相似向量及其对应的对象。

- 下图的示例是针对三维向量的query，返回结果中的**score**表示相似程度，越大表明越相似。





------

# 18-Timeseries Database 时序数据库

### 概念

时间序列数据库（TSDB）是针对时间戳或时间序列数据而优化的数据库。

> 时序数据：比如说一个花园，我在里面布了很多的传感器，这些传感器能检测温度和湿度，我来做这个自动浇灌，然后他们就会源源不断的产生数据，我要把它存起来，那可以看到它们源源不断产生数据，于是我们看到这数据有几个特征。
>
> - 第一个：它的**数据格式是比较简单**的，不像关系型数据库有多个表然后表和表之间还有关联，它实际上就是一**些监控数据**，比如温度，资源利用率utility
> - 第二个：因为格式比较简单，因此可以**不存原值，存差值**。比如有一串温度数据11.1，11.2，10.9，10.8，可以保存成11.1，+0.1，-0.2，-0.3，这样做的好处是可以**节省空间**
> - 第三个：这个数据只要你往上发，它一定**带一个时间戳timestamp**。针对timestamp的存储可以做**优化**，比如我要存13位的学号，前10位所有人都是一样的，那么前10位可以只存一次。timestamp同理，可能很多数据timestamp一样，那么可以之存一次。此外，也可以像第二点一样，存差值，节省空间。
> - 第二个：你一定会有大量的这种传感器在传数据，所以它必须要支持这种**高并发**，就**吞吐量要大**，这种吞吐量必须要大才能支持高并发。
> - 第四个：你说传感器如果他在报数据，他偶尔丢掉一两个或者一两个不太准，它会不会影响你的这个数据整体的效果？
>   就是他如果说每一秒钟都报一个数据，在某一秒他突然丢了一个数据，它会不会影响你做统计的效果？就理论上来说，它里面的**数据允许少量的不准确或者是缺失**，也就是说它的数据和那种 transaction 的数据就形成了鲜明的对比。
> - 第五个：就是其实我们**对单点的数据是不感兴趣**的，你说我要知道某一个时间点，这里面每一秒都要发数据，我要知道在某一秒的数据，这个肯定你不太关心，你关心的是**一个时间区间内**，比如说在一小时内它的数据什么样的，我要去求和，更严谨的说第五个：它的**数据格式是比较简单**的，不像关系型数据库有多个表然后表和表之间还有关联，它实际上就是一**些监控数据**，比如温度，资源利用率utility
> - 第六个：因为格式比较简单，因此可以**不存原值，存差值**。比如有一串温度数据11.1，11.2，10.9，10.8，可以保存成11.1，+0.1，-0.2，-0.3，这样做的好处是可以**节省空间**。所以在持续数据库里，他对单点数据的访问不会特别多，他经常做的是对一块数据，尤其是时间片划分出来的一段数据，他要去做一个访问。

![image-20250115132243168](C:/Users/77043/Desktop/应用/17-18/image-20250115132243168.png)


1. 整体的存放是用了类似lsm日志结构合并树的结构；时序数据库的**生命周期一般比较短**，比如一个传感器，可能我们只关心最近一周的或者一个月的数据，超过的时间的数据就可以删除（比如当掉到L0以下，我们就将其压缩，甚至删除）。（类比关系型数据库的订单数据，订单数据必须要持久化保存，但是这种时序数据库可以**通过摘要压缩一下，或者直接删掉**）
2. 不太可能会建立索引，例如记录温度随时间的变化，一般不会有必要建立索引（比如建个温度在时间的索引，这没有意义）
3. 对于时序数据库接受的数据的特点：格式简单，更多的数据点，更多的数据源，更多的监控，更多的控制

> **Telegraf & InfluxDB**
> InfluxDB是数据库；Telegraf是数据采集器，可以采集各种各样的数据，然后把数据写入到InfluxDB里面去。

## InfluxDB

### query示例：

![image-20250115132343425](C:/Users/77043/Desktop/应用/17-18/image-20250115132343425.png)

![image-20250115132418140](C:/Users/77043/Desktop/应用/17-18/image-20250115132418140.png)

### 基本概念

![image-20250115112418532](C:/Users/77043/Desktop/应用/17-18/image-20250115112418532.png)

- Bucket就是类似于关系型数据库中“表”的概念；没有库的概念，因为不像关系型数据库中有外键关联的概念。
- 带有_开头的，都是系统保留的字段，也就是一定会有的一个列，反之都是用户自定义的字段（比如上图中的location和scientist，他们都是**Tag key**, Tag可以作为筛选的依据，得到一个**Tag set**）。
- _time：时间戳，数据对应的时间，因为可能同一个时间会接收到很多数据，所以很可能同一个时间接收到很多数据，所以时间戳不能唯一的标识。时间戳非常准确，精确到纳秒级别。
- _measurement：起一个名字，一个统称，这个表格在干啥。census就是调查种群数量。这里我们发现它是共享的，所以存储的时候会优化，**只存储一次**。
- _field：存储的是key，比如上图里面存储的就是某个物种的名字；和value构成键值对。Field可以作为筛选的依据，得到一个**Field set**。
- _value：存储的是value，类型可以是strings, floats, integers, or booleans，之所以不能是别的，是因为如果是复杂的数据类型转换会耽误时间，效率降低，所以就只能存这些基础的数据类型。
- 所有的tag都参与索引，而field是不参与索引的（从语义上说，tag的东西都是用来“修饰”_field的，比如上图中的）

### Schema优化

上图中，location和scientist都属于Tag，_field和 _value都是Field。Tag和Field之间是**可以相互转化**的

- **Fields不参与索引**，必须扫描全表；如果经常被访问，就表明不适合以这种形式存储，就应该以Tag的形式存储。
- **Tags参与索引**，当然查询起来就会更快。当然索引本身是有开销的，并且如果你进行写操作，索引也会更新，带来更多开销。

考虑以下的示例：

![image-20250115112958636](C:/Users/77043/Desktop/应用/17-18/image-20250115112958636.png)

如果经常会做上述的query，那么事实上我们不用每次都去做全表的scan。如果在bees这一列上**按value的值做过索引**，那么query会更快。修改下图所示

![image-20250115113417014](C:/Users/77043/Desktop/应用/17-18/image-20250115113417014.png)

### influx中的其他基本概念

- Series：measurement, tag set, 和field key都相同的点集合，统称为series key。

![image-20250115113737233](C:/Users/77043/Desktop/应用/17-18/image-20250115113737233.png)

- Point：一个数据点，带有时间戳的数据点。
  比如 `2019-08-18T00:00:00Z census ants 30 portland mullen`
- Bucket：存储桶，包含**数据库**和**存活时间（retention period，即每个数据点能持久化存在的时间，时间一过就会删除掉）**这两个概念。归属于一个组织，存储相对应的数据点集合。
- Organization：组织，一组用户共同的工作空间，他们会看到相同的bucket，dashboard等。

### InfluxDB设计原则：何以支持时序数据？

- **严格按照时间组织**，按照时间顺序递增追加append（write in time-ascending order），不会出现说我突然插入一个以前的时间戳
- **严格限制update和delete**。首先本来就是传感器送过来的数据，你改它干吗？而且，你明明一直在追加，你说我往里面去改写，那它就不是顺序读了，它要做一次随机读，它效率就降低了。改一下有可能尺寸会发生变化，要么留下空洞，要么它存不下后面东西所有都要往后挪，所以它就严格限制你不能这么做。所以他认为时序数据就是新数据，而不是一个数据的不同版本（所以和RocksDB有差别）。
- **数据的读写优先**。你数据库里就是读和写，然后你说他们优先，那还有啥东西？就是我们的数据库InfluxDB，那它也许会是分布式处存储的，那它可能一主两从，那你这些中间是不是就会有同步的问题？这是一个动作，这是他内部要去实现的，但是他就告诉你，如果你现在有这个读和写，就指的是用户发送过来的读和写的要求的话，必须优先处理，哪怕你没同步好也要处理。比如当数据的接入率非高的时候（multiple writes per ms），这个时候query会类似“冻结”一样，只把当前时间之前满足的数据返回给你，在执行过程中之后进来的数据是找不到的，因此**有可能找不到最新的数据**。它实现的是**最终一致性**，而不是实时一致性。因为它认为系统的实时性比较重要——开始我们讲过了，我们是允许时序数据中一些小小的错误的。
- **幂等性**。应用场景里面就是大量的传感器，会把大量的数据通过不可靠的或者不那么可靠的网络传递过来，那我就不能保证它没有被发送多次，但是它发送多次它也不能对我的数据库产生影响，我只存一个（根据时间戳）。比如除了value之外的部分数据都是相同的，这样的数据提交了三次，不会像MySQL一样插入三行相同的数据，InluxDB会用最新的一个数据存储。
- **没有传统意义上的ID**。因为数据集比单点数据更重要，id是来区分每一条数据和其他数据之间的差异，用ID是因为我们要拿单点数据，但对于时序数据库我们没有这一需求。所以InfluxDB实现了强大的工具来聚合数据和处理大型数据集。点通过时间戳和series key来区分，因此没有传统意义上的ID。

### Storage Engine 存储引擎

![image-20250115115501011](C:/Users/77043/Desktop/应用/17-18/image-20250115115501011.png)

整体是TSM（Time Structured Merge Tree）结构，类似于LSM的结构。

###### 2.5.1 Writing data from API to disk

![image-20250115120140389](C:/Users/77043/Desktop/应用/17-18/image-20250115120140389.png)

**关键概念：**

- **Line Protocol：**采用**Line Protocol**来将数据写入硬盘。它本质上可以视为一种“键值对 + 时间戳”格式。与JSON类似，但在序列化和传输时有特定的格式，旨在更高效地处理时序数据。之所以高效是因为InfluxDB提供了RESTful的HTTP接口来接收数据,通常使用`POST`方法提交数据到指定的写入端点（如 `/write`），数据在传输过程中以字符串（或类 JSON）形式封装，方便批量写入。
- **数据写入流程：**
  1. **客户端发送数据**
     - 通过`POST`请求将数据发送到InfluxDB，数据可包含一个或多个“点”（Points）。
     - **批量发送**：为降低网络和接口压力，通常会将多条数据（多个点）批量发送，而非单条单条发送。
  2. **接收数据与压缩**
     - InfluxDB接收数据后，会对相同或相似的部分进行简单压缩（如“相同数据只存一次，然后记录数据出现的范围”）。
     - **目的**：减少写入量，避免预写日志（WAL）迅速膨胀。
  3. **写入WAL（Write-Ahead Log）**
     - 数据在正式持久化到底层存储之前，会先写入**WAL**。
  4. **内存缓存（Cache）**
     - 查询可见性：只要数据到达Cache，便可被查询到（类似于前面介绍的 RocksDB/LSM Tree 的MemTable机制）。
     - 当Cache达到一定阈值或时间周期到达时，才会将数据 **刷新（Flush）**到硬盘。
  5. **持久化与 Compaction**
     - **多层存储（L0 ~ Ln）**
       - InfluxDB采用类似LSM Tree的结构，数据从内存落盘后会形成新的文件（如L0层文件）。
       - 随着数据量增多，文件会不断往更低层（L1、L2…Ln）合并，类似RocksDB的层级结构。
     - **Compaction（合并操作）**
       - 当某层文件数量过多或文件规模过大时，需要执行Compaction**将多个文件合并，删除或合并重复数据，生成更大、更有序的新文件。
       - 目的：减少文件数量、优化查询性能、回收无效空间。

###### 2.5.2 Write Ahead Log(Log)

![image-20250115120140389](C:/Users/77043/Desktop/应用/17-18/image-20250115120140389.png)

**关键概念：**

- **顺序写入日志**

  - 当存储引擎接收到写请求后，首先将该请求写入预写日志（WAL）。

  - WAL采用顺序写的方式，将写操作记录（如新增或更新的数据）依次追加到日志文件中。

- **同步日志到硬盘**

  - 为确保数据可靠性，存储引擎会将预写日志刷新（Flush）到硬盘。

  - 只有当日志文件同步到硬盘之后，系统才认为该写操作有了“落盘保障”。

- **数据写入内存**
  - 日志同步完成后，存储引擎才将数据缓存到内存（通常是MemTable、Buffer Cache等），便于后续的快速读写和处理。

- **写操作完成**
  - 当WAL同步和数据入内存等关键步骤执行完毕后，存储引擎才向调用者返回“写操作完成”的确认。

###### 2.5.3 Cache

![image-20250115121646000](C:/Users/77043/Desktop/应用/17-18/image-20250115121646000.png)

**关键概念：**

- **Cache 与 WAL 的关系**

  - 当写请求到来时，先将数据写入**WAL**（写之前可能先压缩），以减少对WAL的写入量和存储占用。

  - 随后，数据会被放入内存**Cache**中，方便快速访问与查询。

  - 在一定时间或空间阈值触发后，数据再从Cache合并落盘至底层文件。

- **Cache 中的数据组织**

  - **Series Key**：由**Measurement**、**Tag**以及**Field**等信息组成，标识了同一组数据在不同时间点的记录。

  - **按 Key 存储**：Cache以Series Key为单位组织数据，相同的Key会被汇总在一起。

  - **时间顺序排序**：在同一个Series Key下，数据按时间戳顺序排列，便于时序查询。

- **“热”数据特性**

  - **内存中不压缩**：Cache中的数据（最热的数据）为了保证快速读写，不进行压缩。

  - **快速访问**：由于在内存中，查询时对热数据的读取延迟极低。

  - **动态合并**：随着时间推移或数据增长，Cache中的数据会批量合并到更低层的持久化文件，腾出Cache空间。

- **合并流程（Compaction）**

  - **周期或阈值触发**：在达到设定条件（时间、空间）后，Cache中的数据被合并写回磁盘文件。

  - **RocksDB式分层**：底层文件采用类似LSM Tree的多层结构，通过合并操作（Compaction）维持数据有序并释放冗余空间。

  - **查询可用性**：在合并的过程中，Cache中以及合并后的文件都能持续支持查询请求。

###### 2.5.4 Time-Structured Merge Tree(TSM) & TSM files

![image-20250115122455139](C:/Users/77043/Desktop/应用/17-18/image-20250115122455139.png)

**关键概念：**

- **文件层次与合并（Compaction）**

  - **多文件合并**
    - InfluxDB的底层文件在写满或定期触发时，会进行合并（Compaction）操作，将多个小文件重新整理、去重、压缩后合并为更大的文件。
    - **按时间或按Series Key范围** 划分文件，合并时也会考虑Series Key的分布以便有序存放。

  - **数据“冷热”分层**
    - **写入Cache的数据**：视为“热”数据，未压缩，便于快速读写；
    - **落盘文件**：视为“冷”数据，进行压缩以节省存储空间；合并后再以较大文件形式存储。

- **列式存储(Column-Oriented Storage)**

  - **为什么采用列式？**
    - **典型时序场景**：频繁对某个或几个Field（字段）做分析或聚合，需要对单列进行大规模顺序扫描（Scan）。
    - **顺序读性能更高**：列式存储将同一列的数据集中在一起，便于大块读取。

  - **数据组织方式**
    - **Series Key**：由Measurement、Tag、Field等信息组合而成，标识同一“系列”数据。
    - **同一Series Key内部**：按时间顺序排列数据；多条数据打包在同一文件块（Chunk）中，并采用列式格式存储。

- **压缩与 Delta 编码**

  - **差值（Delta）存储**
    - 为降低空间占用，对数值型数据（如CPU利用率）通常只存储相邻记录间的“差值”（Delta），而不是原始值。
    - 基准点 + 差值：
      1. 先记录一个基准值（如50%）
      2. 后续每次只存“与前一次记录的差值”（+1%、-2% 等）
      3. 定期刷新新的基准点，减少误差累积。
    - **优点**：显著减少存储空间占用；
    - **缺点**：查询任意时间点的数据时，需要先找到基准点，再累计所有差值才能复原。

  - **列式压缩**
    - 同列数据往往类型和分布相似，更易采用高效的编码方式（如前几位相同，所以只存后几位、或仅存变化量），从而进一步降低存储量。

- **与 SSTable 的对比**

  - **相似点**
    - **日志结构**：写操作先顺序追加，后续合并（Compaction）生成有序文件；
    - **共享前缀/共享字段**：只记录差异部分，节省存储空间；
    - **按Key排列、分块存储**：可快速定位Key范围，提升查询效率。

  - **差异点**
    - InfluxDB主要面向时序数据，列式存储、Delta 编码尤为常见；
    - 一些传统的SSTable仍以行式或前缀压缩为主，未必都做列式拆分。

###### 2.5.5 Time Series Index(TSI)

![image-20250115123453161](C:/Users/77043/Desktop/应用/17-18/image-20250115123453161.png)

**关键概念：**

- **基于 Series Key 的索引**

  - **Series Key**
    - 由Measurement、Tag、Field等组成，用于唯一标识一组时序数据。
    - TSI主要围绕Series Key构建索引，用来快速定位具体时序数据。

  - **索引结构简化**
    - 在传统关系型数据库中，索引种类繁多（B+树、哈希、前缀索引、地理空间索引等），可自定义多列、多种排序方式。
    - 时序数据库（TSDB）则不需要如此复杂的索引结构：
      1. 时序数据查询模式相对固定，多基于 (Measurement + Tag + Field) 的组合。额外索引（如多列任意组合）意义不大，且会增加索引维护成本。
      2. **只需维护Series Key索引** 即可快速查到相应的时间序列。

- **查询过程示例**
  - 指定 Measurement、特定 Tag 或若干 Tag、以及需要读取的 Field。
  - InfluxDB 通过 TSI，先找到满足 (Measurement + Tag + Field) 的 **Series Key**，再返回对应时间序列。

- **对比关系型数据库索引**

  - 关系型中的灵活索引
    - 可以任意指定单列、多列、前缀、顺序等，甚至支持空间索引。
    - 查询模式更加多变，需要更通用的索引策略。

  - TSDB 的简化模式
    - 查询模式围绕时序和少数固定字段，索引只需简单且高效地支持 (Measurement + Tag + Field + Time)。
    - 数据库内核也无需维护大量复杂的索引结构。

### influxDB file system layout

![image-20250115125835877](C:/Users/77043/Desktop/应用/17-18/image-20250115125835877.png)

### InfluxDB shards and shard group

![image-20250115130656506](C:/Users/77043/Desktop/应用/17-18/image-20250115130656506.png)

**关键概念：**

- **Shard 与 Shard Group 的定义**

  - Shard：
    - 时序数据在硬盘上的基本存储单位，通常已经经过压缩和编码。

  - **Shard Group：**
    - 对特定时间范围的数据进行分组管理的逻辑单位。
    - 例如，可将**1 天**定义为一个 Shard Group，再细分出若干个Shard（企业版）；在OSS中，每个Shard Group仅包含一个 Shard。

- **时间范围（Duration）的配置**

  - Retention Policy（保留策略）

    - 指定数据保留的总时长，例如保留4天的数据，超过4天自动删除。
    - 也可设置为 “forever” 不自动删除，具体视业务需求。

  - Shard Group Duration

    - 例如，可将 “1 天” 作为一个 Shard Group 的持续时长；在此之下再根据需要划分 Shard（如1小时一个 Shard）。

    ![image-20250115131125328](C:/Users/77043/Desktop/应用/17-18/image-20250115131125328.png)

    - 当新的时间段开始时，自动创建新的Shard Group并删除过期的旧Shard Group（由 Retention Policy 决定）。
    - **Precreation（预创建）**：可提前创建未来时间范围内的Shard Group，避免在数据刚到来时再去建Shard Group耗时。

  ![image-20250115131250435](C:/Users/77043/Desktop/应用/17-18/image-20250115131250435.png)

- **数据“冷热”分层与写入流程**

  - 最新写入的数据
    - 位于内存缓存（热数据）或刚创建的Shard（活跃 Shard），此时往往尚未压缩，利于快速写入和读。

  - 压缩与落盘
    - 当 Shard 不再是活跃状态，数据落盘后会进行更强的压缩（TSM 文件），减少存储空间占用。
    - 落盘后的 Shard 即可视为相对“冷”的数据，未来只读不写，便于在时间到达后直接删除。

  - Compaction（合并）
    - 采用类似 LSM Tree 的多层结构（L0/L1/L2/...），数据批量往下合并，减少文件数量并整理数据。
    - 每一层比上一层存储容量可大一个数量级，默认配到 L4、L5 即可满足相当大的数据规模。

  ![image-20250115131325422](C:/Users/77043/Desktop/应用/17-18/image-20250115131325422.png)

- 自动管理与删除机制

  - 自动删除旧 Shard
    - InfluxDB 会根据 Retention Policy **周期性地**删除过期的 Shard Group，无需人工干预。
    - 例如，保留 4 天的数据：当第 5 天开始时，创建新 Shard Group 的同时，删除第 1 天的 Shard Group。

- 与传统数据库的区别

  - 传统数据库通常需要用户手动指定何时删除或归档数据；

  - InfluxDB 面向时序场景，系统自动完成旧数据的删除和新Shard Group的创建（都在配置文件中设置）。

![image-20250115131542491](C:/Users/77043/Desktop/应用/17-18/image-20250115131542491.png)





------

# 19-GaussDB技术架构

GaussDB基于Postgrade SQL9.2版本写成，但是后期做了一些改进，例如把原本的单机改成了分布式，多进程变成多线程，总的来说是做了分布式优化。分布式会遇到两阶段（2-phase）提交的问题，如何知道某个数据能否提交？第一阶段先做prepare，问系统能不能提交，第二阶段才做提交或者回滚，做了一个决策，所以他做了一个很复杂的分布式事务，然后在上面又做了分布式的优化。例如用户给出一个SQL，在用户不知道分布式存储的情况下，GaussDB做了关系运算的优化。  
GaussDB的最底层做了一个分布式共享存储，所谓的分布式共享存储，是对用户来说是一个数据库，用户感知不到分布，所谓共享，就是实现了存算分离（存储和内存分离）。在单片机中有DMA的概念，基于这个想法，把所有节点的内存单独拿出来，凑成一个分布式的盘存，再把硬盘全部拿出来凑成一个网盘，如果支持一个机器上的内存去读另一台机器硬盘上的数据，就实现了一个remote DMA。云数据库把所有机器上的内存组成一个大的内存，所有的硬盘组成一个大的网盘，做了一个内存和存储，即磁性化存储和顺式性存储的分离，那么看起来就是一个特别大的机器有特别大的内存和特别大的硬盘，那他的数据保温性能就会提高。

## 具体事务管理有

1. 分布式的近数计算，就是我们的处理应该靠近数据（靠近存储数据的那一层），在前面的样例中就是计算节点，这样能提高执行效率
2. 全链路并行编译执行，也就是把语句先编译一下，把参数填进去执行，相比SQL语句的解释执行要快
3. 大规模并发事务处理。

## 具体分布式优化

1. 一个SQL语句过来先解析生成query plan，把原先的写的不好的地方优化一下再执行
2. 第一个可以给一些固定死的优化的规则，不管SQL是什么情况都基于这个规则去做（RBO）；第二个是基于代价，即需要评估现在的这个SQL语句读取的硬盘或者网络传输的代价（CBO）。
3. hint，即用一些类似于annotation的东西，去告诉query plan的优化器大概可以怎么做，去生成一个更好的东西。
4. 计划管理
5. SMP，用对称的多核的机器做并行处理
6. 相比Postgrade新加了线程池
7. 向量化，在数据存储的时候可以有行存也可以有列存，可以一次读取一列上面的多行的数据。     
   其余的还有（上课没讲但是PPT上有）段页式，Paxos，增量检查点，ACID，AStore，UStore，CStore，MOT。HTAP：行列混合存储（OLTP），智能行转列（OLAP）

## 多层级高可用容灾

一般在单机的时候不会考虑，但是这里的容灾包括了多地多活的容灾，一般是两城三中心，就是在两个城市里面有三个数据中心，他们互相之间备份。

## 云原生弹性伸缩架构

即假设当在线人数很多，请求数很多，数据存储不下了，需要做在线的弹性伸缩，一般分成两个方向，纵向是多分配给原先的机器、原先的实例一些计算资源，横向是原先只有一台机器，现在新加一台机器，变成一个集群，这里纵向横向都可以做。有云原生分布式计算存储分离，把内存层硬盘层CPU层变成三个集群，合起来看就像是一台超级计算机在运行，这样引申出了负载均衡、分布式多写多读、多租户（这个等会展开来讲）

## 智能优化

这里有一个很重要的ABO优化器，是之前RBO和CBO的一个补充，全拼是AI Based Optimize，意思就是无论是代价的评估还是启发式的选择，都可以通过AI方式以及生成式的AI来帮忙处理，因此内置了AI引擎，内置了实现好封装好的算子，例如矩阵乘法或者神经网络的前馈或者反向传播

## 安全隐私保护

利用了区块链来防篡改，区块链是非对称密钥的应用

# GaussDB分布式架构

![GaussDB分布式架构](C:/Users/77043/Desktop/应用/19-20/GaussDB分布式架构.png)  
分布式优化器（Coordinator Node）协调所有的Data Nodes，真正存数据的节点，协调数据一致性以及做事务的时候向两边提交的事务。全局分布式事务（GTM）做事务管理

# GuassDB分布式优化器

![GaussDB分布式优化器](C:/Users/77043/Desktop/应用/19-20/GaussDB分布式优化器.png)

## 查询重写

目的是根据底下的分布式的存储状态、底下机器的定形的优化和对称的多核处理器的优化，改写逻辑优化的查询计划。  
数据库最后逻辑优化出来的查询考验数据库的能力，例如同样的一个查询在不同数据库优化后的查询树执行一下，看看执行效果。但是有些种类的查询可能在某些数据库上查询较好，但是另外一些又反过来，也就是说，目前没有一种优化器，对于所有的优化，都做得比别人好，原因是优化器的过程很多是顾此失彼的。这张图上还只是传统的RBO和CBO，那么有些数据库可能封装了更多AI算子，那么效果可能更好。  
还有一个要注意的地方是要做好一个平衡，例如假设不优化需要1s，优化过程需要800ms，优化以后需要执行500ms，看起来优化了一下时间缩短了一半，但是不是看起来很高级的算法一定能做出一个很好的结果

# GaussDB分布式并行执行

1. 前提条件是任务必须满足批处理的结果，也就是大家并行做出来的结果合并以后就是最终结果，后面讲到Hadoop的时候会讲到这个问题，这就是多机多线程并行执行。  
2. 向量执行很像python里面的维度拓展，对于一个多核处理器，每一个核都能处理一个列里面的一个值，那么处理一个向量和处理一个单独数据消耗的时间是一样的，那么这里就支持单条指令中多个数据的处理。  
3. 由于底层虚拟机（LLVM）使用的时候可以像流水线一样加载一些指令，因此可以编译执行

# GaussDB两地三中心

同城两中心，异地有一个第三中心作为容灾机群，除非两个城市的三个中心都出现问题了，数据才不能用。这里三个中心中只有一个DN是主节点，其他都是备份节点，需要进行同步操作（CSE中的）

# GaussDB多租户

当同一个实例给不同人用，提出的不同的需求应该怎么办？方案一生成不同的数据库，方案二是大数据控制，方案三是在后面新加的字段标注是哪个用户的，每个用户只能看到自己加上去的字段，方案四，把列转成行，后面新加的数据用行存，每一行分别存主键、新加的字段以及对应的值，缺点是可能表很大，但是后三种都实现了多租户。GaussDB可以选择用哪种方式实现。现在的数据库可以支持底下芯片的异构，然后以统一的方式去维护

# GaussDB优化处理

RBO：根据启发式规则进行优化，即现在全局可能有一个最优解但是目前找不出来，然后通过一定的方式去计算，例如牛顿切线法以及贪心，按梯度走。还有一个元启发，就是在原先找到的局部最优下，冲出去一点找有没有新的局部最优，也就是说可以确立一个新的起点  
CBO：这里的代价包括读取的列数、行数（IO开销）、通信开销、CPU开销等等，包含了好几部分，然后基于AI模型估计这个代价是多大，还有统计信息：表级别的有总元组数、总页面数，列级别的有空值率、不同的值有多少。

# GaussDB计划生成

主要采用自底向上和随机搜索相结合的模式

# GaussDB存储

## 追加更新

主要是行存（追加更新行存、原位更新行存）和列存，还有智能化的互转，并且内存可以做数据全内存的存储，就像自带Redis。
![GaussDB存储结构](C:/Users/77043/Desktop/应用/19-20/GaussDB存储结构.png)
堆表主要是三层大根堆，用于管理内存的空闲空间。在数据插入的时候需要高效找到空闲空间足够的页面，插入数据后还要能够高效更新页面的空闲空间大小
![GaussDB页面结构](C:/Users/77043/Desktop/应用/19-20/GaussDB页面结构.png)
![GaussDB多版本](C:/Users/77043/Desktop/应用/19-20/GaussDB多版本.png)
![GaussDB追加更新](C:/Users/77043/Desktop/应用/19-20/GaussDB追加更新.png)
追加更新中xmax=0表示该数据仍然有效，t_ctid表示该数据失效后应该找哪条数据
![GaussDB追加更新2](C:/Users/77043/Desktop/应用/19-20/GaussDB追加更新2.png)
每个事务有一个单独的事务状态存储区域，记录了该事务的状态信息和提交顺序号（CSN）。每个非只读事务的事务号为XID，在事务提交时会增加CSN取值。  
CSNLog：记录XID与CSN的映射关系，为每个事务生成一个唯一递增的CSN，用于将事务与其可见性进行关联  
Clog：记录事务ID的运行状态：运行中/提交/回滚。当事务结束后，使用CLOG记录是否提交，使用CSNLOG记录该事务提交的序列

## 原位更新

![GaussDB原位更新](C:/Users/77043/Desktop/应用/19-20/GaussDB原位更新.png)
![GaussDB原位更新2](C:/Users/77043/Desktop/应用/19-20/GaussDB原位更新2.png)
优点是保证数据段紧凑并且不用做多版本控制，因为各有优劣所以GaussDB两个都支持，行存储索引用的是B+树  

## 缓冲区

GaussDB对事务的读写请求，都会被先传递至共享缓冲区。请求页面利用Ring Buffer操作批量读、批量写、以及页面清理，会先在缓冲区搜索该页面，如未命中，则获取一个空的槽位（可能需要淘汰掉缓冲区中不常用的页面），再与文件系统进行交互将所需页面读到槽位中，加锁并使用。高并发Hash table：采用分区锁避免读写hash table冲突。  
Buffer页面的冷热管理
1) buffer ring策略:  避免顺序扫描读取页面导致大量淘汰温热buffer
2) never evict策略：基于规则避免页面被淘汰
3) LRU策略：识别冷热页面，提高buffer命中率
![GaussDB缓冲区](C:/Users/77043/Desktop/应用/19-20/GaussDB缓冲区.png)

## 并行日志系统

事务提交仅保证事务相关的预写日志WAL持久化完成，WAL模块在内存中维护了WAL缓冲区用于各个事务的WAL日志并发写入缓存区，提高性能。后台刷WAL日志线程需要顺序从WAL 缓冲区读取WAL日志完成持久化。在每个事务提交之前，需要判断已经刷新的WAL LSN是否已经包含了本事务的WAL。用全局的锁控制多进程输入。

## 列存储

![GaussDB列存储](C:/Users/77043/Desktop/应用/19-20/GaussDB列存储.png)
为了管理列存表的CU，列存储引擎使用压缩单元描述符（CUDesc）表来记录CU的元信息。CUDesc的一行对应一个CU，记录了CU的事务时间戳信息、大小、存储位置等信息。  
![GaussDBCU文件结构](C:/Users/77043/Desktop/应用/19-20/GaussDBCU文件结构.png)
列存储的B+树索引:与行存类似，列存B+树的索引页面上存储键到ctid（页面号，元组槽位）的映射，ctid记录的是CU的编号，还需要通过CUDesc进一步查找。  
列存储的稀疏索引：CUDesc存储每个CU中数据的最小值和最大值。读CU前可以根据查询条件进行判断，如不在不在最小值和最大值之间，则可以不读取该CU，大量减少I/O的开销。  
列存储的聚集索引：不同CU间最小值和最大值的区间有大量交集时，稀疏索引可能无法提升效率。聚簇索引对部分区间内的数据排序（一般区间会包含多个CU），由此减小CU之间数据的交集，使CU内部的数据有序，提升CU文件本身的压缩效率。

## 内存引擎

类似于Redis，支持全内存态的数据存储与事务处理。  
低延迟（Low Latency）：提供快速的查询和事务响应时间。  
高吞吐量（High Throughput）：支持峰值和持续高用户并发。   
高资源利用率（High Resource Utilization）：充分利用硬件。  
具备并行持久化、检查点、高可靠、免锁事务管理、免锁索引等能力。  

采用外部数据封装器FDW（Foreign Data Wrapper）方式将内存引擎插入数据库。数据可以是外面的数据，拉进来之后经过格式转换，变成内存里的数据存储。  
这些都是为了HTAP的数据支撑，既支持OLAP又支持OLTP

# GaussDB分布式事务

全局事务管理器GTM处理全局时间戳请求，即CSN（Commit Sequence Number，待提交事务的序列号，是全局递增的一个变量）。  
首先，获取本地最新的CSN和准备阶段事务号，如果CSN状态为“提交中”则进行等待，如果row.CSN < localsnapshot.csn || xid in prepared_xid list可见，否则不可见。
![GaussDB分布式事务](C:/Users/77043/Desktop/应用/19-20/GaussDB分布式事务.png)
只要在第一阶段达成了一致，事务就可以结束，去做其他事情。  
判断事务的发生的先后需要用高精度的时钟，例如北斗这样的卫星，对所有的服务器进行定位。分布式系统一定要有一个统一的授时单位，目前可以用北斗

## 查询优化

传统汇聚分布式：假如节点1和节点2的数据需要合并，那么需要这两个节点把数据推上来进行合并。  
协调节点旁路技术：把节点1和节点2的数据在处理的时候保证在同一个节点上，但是很难。  
数据节点自协同的流式计划：最好情况是两个节点内部各自做大量的计算，然后有少量数据进行节点之间的互相访问，最后两个节点的结果在协调节点合起来就是最终结果。只需要t2的分区和t1的分区相同即可。如果不同，有两个方法。如果表2比较大，直接做一个重分布，但是会比较费时，因为需要有数据的移动和传输。表2比较小的话可以把数据广播到其他所有节点上，那么表1所在的节点也就能接收到数据。分布式的优化就是不要在节点之间传大量的数据。  
生成分布式物理计划时，会考虑数据是否处于同一个数据节点，如果不是，那么会添加相应的数据分发算子。根据分发算子的数据量以及网络通信开销， GaussDB优化器计算计划的代价，并根据代价从中选出最优的物理计划。  
云原生中这些节点之间都是通过高速网络连接

# GaussDB云原生

分布式计算存储分离：计算与存储解耦，实现计算资源池和存储资源池独立扩缩容，分层弹性。  
存储节点按需回放: 存储节点实现日志回放，大幅减少计算节点和存储节点带宽压力。我们做的所有操作都记录到日志里面，提交操作到哪个节点上都是透明的，崩了之后可以在其他地方利用这个日志回放成跟原先一样的数据。  
数据预分片: 结合底层分布式存储，实现数据预分片能力，不用每一次数据进来的时候再分片。缩短扩容时间，实现业务平滑扩容。  
哈希桶聚簇存储：把表文件拆分为多个分片，采用一致性哈希算法，扩容时，只需重分布少量数据可实现扩容。  
映射表并行迁移:  用户数据不迁移，仅迁移少量元数据映射表，实现数据在数据节点的重分布，达成扩容目标。  
全局回放点计算：收集所有备机回放进度，计算全局一致性点，即协调节点。  

# GaussDB高可用

生产集群，热备集群：实时备份的集群，一个请求同时发到主从集群里面，对用户来说切换时间几乎是0，丢失的数据也几乎是0（RPO=0），但是也浪费资源。暖备集群，收到请求但是不执行，等到生产集群的结果出来再备份，如果这个时候生产集群崩了就备份失败，会要求重发一次。冷备集群是周期性的进行备份，为了防止发现很长一段时间崩掉无法备份，通常很短的时间进行一次主从切换（例如5min）。

# GaussDB安全全景

1. 攻不破：攻击进来首先要做一个模式的识别，知道是不是攻击，然后检测是不是有威胁，有没有异常行为，防止一些恶意代码的注入（例如脚本）
2. 进不来：指我也不会去攻击你，用公私钥对、黑白名单、第三方如KerBeros进行认证
3. 拿不走：做权限设计，基于决策、基于访问权限的设计，能做到行级别的
4. 看不懂：数据脱敏，动态或者静态的脱敏，做一些编码和数据一起输入。数据加密，首先很难解密，其次就算解密了，修改以后没有私钥也保存不了，改了也没用。一般用的都是非对称密钥（包括SSL）
5. 改不了：用账本数据库机制，核心是区块链
6. 赖不掉：因为有log的存在，每次操作都会记录下来，抵赖不了，包括语句审计，用户审计，数据库水印等
7. 信得过：通过了一些第三方认证，例如GDPR，CC认证





------

# 20-data-lake

之前的数据库例如MongoDB、InfluxDB都有云数据库，注册一个账号就可以用，但是现在有一些不同数据库里面的数据，需要放到一个系统里面，未来要做OLAP。那么就有一种软件叫做Dataware House（数据仓库），作用是接一些适配器，每个适配器负责一个数据库的数据读取，读进来以后放到一张表或者一个立体一样，将来分析的时候直接在这个多维的数据表上面分析。但是在这个分类读取和整理的过程中耗费了大量的代价，一般都要经过三个过程。E（extract），把数据从原始的表里面提取出来，T（Transform）把原始的数据转换成统一的单位，L（Load）加载到统一的表里面，如果原始的表很大就会非常耗时间。但是假如不知道什么时候对于这些数据进行分析，那么只需要把这些数据存放下来即可，等到需要分析的时候再去做ETL，那么数据湖就是解决这样一个存放数据的问题。  
数据湖是一个存储池，存的时候没有ETL的操作，就是按照数据原来的格式，一般来说是图文件或者较大的文件，还需要有一个元数据去描述它的格式。里面包含结构化的数据，也可以是非结构化的数据。  
湖的前方会有一个类似于Flink这样的工具，把数据接入进去存放进去，然后配一个metadata描述他在干嘛，要访问的时候先去读取metadata，看是什么格式，是不是自己要的，找到之后再去做ETL。  
但是假如用户的Query语句设计了MySQL和MongoDB两个数据库的内容，需要在元数据里面发现操作的数据集是这两个，要把SQL语句转化为这两个数据集的调用，但是有专门的工具，例如calcite。  

## Delta Lake

数据湖里面有几个不同产品。最常用的叫Delta Lake，它支持各种结构化、半结构化、非结构化的数据类型，可以高速接入各种类型数据并且保真存储，原来的格式是什么就存什么。它的处理可以是实时处理也可以是批处理，可以用SQL或者第三方的语言去进行分析。分析的方法是把所有数据转成统一的格式，例如Parquet这种二进制格式，几乎所有数据库都支持把他们的数据转换成这个格式，那么也就是说，它可以成为一个数据交换的一个标准。

## 数据湖和数据仓库的区别

|              | 数据湖             | 数据仓库             |
| ------------ | ------------------ | -------------------- |
| 数据格式     | 原生的             | 经过处理的           |
| 数据使用时间 | 不是现在           | 现在正在使用         |
| 用户         | 数据科学家         | 商业处理             |
| 能力         | 高可用性和可更新性 | 更复杂、修改更花时间 |

## 演化历程

HDFS（集群）->YARN（分布式计算框架）->数据湖  
HDFS批处理无法满足实时性要求高的场景，因此产生了lambda架构“流批一体”。流是源源不断的，因此需要加一个实时处理的层，filter必须马上过滤完，在原先的批处理引擎上增加了流处理引擎，形成了lambda架构。进来的数据既可以以流的方式处理，也可以以批的方式处理，最终都放在一个统一的数据存储的地方。对外服务的时候也有流处理和批处理两种方式。  
现在对流处理划定一个时间窗，对这个时间窗内的内容进行统一处理，那么在每个时间窗内就是一个批处理，那么流处理就可以按照批处理的方式去分析，无非就是调整时间窗的大小，那么只需要一个批处理引擎就可以实现流批一体。

## 架构

![数据湖架构](C:/Users/77043/Desktop/应用/19-20/数据湖架构.png)
![数据湖架构演化](C:/Users/77043/Desktop/应用/19-20/数据湖架构演化.png)
最后一种湖仓一体的存储方式，数据是否需要ETL由具体用途决定，但是不需要额外进行ETL，在这个湖仓一体的里面即可完成。  
现在的数据湖底部基本上是HDFS或者亚马逊S3或者微软的Azure。
![Hudi](C:/Users/77043/Desktop/应用/19-20/Hudi.png)

## 云边融合数据存储服务

软院4号楼里面有一个小的服务器基站，那么这就属于边缘节点，来供给我们边缘设备的计算与存储例如摄像机、手机等等，由边缘服务器定期把数据传到核心机房里面，在上传的时候数据会经过一些压缩处理，可以减少带宽占用。那么现在的问题是，我现在在中心节点需要查找一些数据，他们存在边缘节点里面，如何确定这些数据存在哪个边缘节点里面？会生成查询计划，推到各个边缘节点里面查询，边缘架构需要采用KV方式存储
![云边融合](C:/Users/77043/Desktop/应用/19-20/云边融合.png)
所以在查的时候添加了全局数据索引：B+树、布隆过滤器、Rosetta过滤器、Mini-Rosetta过滤器
![云边融合分析](C:/Users/77043/Desktop/应用/19-20/云边融合分析.png)
下推可以充分利用边缘节点的算力并且减少数据传输量